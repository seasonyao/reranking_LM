{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Optional, Tuple, Union, Any, collections\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import copy \n",
    "\n",
    "from packaging import version\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from transformers import Trainer, TrainerState, TrainingArguments\n",
    "\n",
    "\n",
    "from transformers.file_utils import (\n",
    "    WEIGHTS_NAME,\n",
    "    is_apex_available,\n",
    "    is_datasets_available,\n",
    "    is_in_notebook,\n",
    "    is_sagemaker_distributed_available,\n",
    "    is_torch_tpu_available,\n",
    ")\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    SequenceClassifierOutputWithPast,\n",
    ")\n",
    "\n",
    "from transformers.utils import logging\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "MAX_LEN = 128\n",
    "CAN_NUM = 5\n",
    "num_of_rerank = 10\n",
    "sample_every = 1000\n",
    "\n",
    "# some parameters I cooked up that work reasonably well\n",
    "epochs = 5\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 1e2\n",
    "epsilon = 1e-8\n",
    "\n",
    "global debug\n",
    "debug = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm not really doing anything with the config buheret\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "VOCAB_SIZE = configuration.vocab_size\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGPT2LMHeadModel(GPT2LMHeadModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "#         self.rerank_transformer = GPT2Model(config)\n",
    "        self.rerank_linear_head = nn.Linear(config.n_embd, 1, bias=False)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        # Model parallel\n",
    "        self.model_parallel = False\n",
    "        self.device_map = None\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        labels=None,\n",
    "        use_cache=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "        is_training=False,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "            Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\n",
    "            ``labels = input_ids`` Indices are selected in ``[-100, 0, ..., config.vocab_size]`` All labels set to\n",
    "            ``-100`` are ignored (masked), the loss is only computed for labels in ``[0, ..., config.vocab_size]``\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        global debug\n",
    "        # make some model parameter not change during rerank (like dropout)\n",
    "        model.eval()\n",
    "        \n",
    "        debug['input_ids'] = input_ids\n",
    "        debug['attention_mask'] = attention_mask\n",
    "        debug['labels'] = labels\n",
    "\n",
    "        rerank_places = random.sample(np.arange(1, MAX_LEN-2-CAN_NUM*2).tolist(), k=num_of_rerank) #no duplicate\n",
    "        rerank_places = np.concatenate(([0], np.sort(rerank_places), [MAX_LEN])) #add first and last tokens to make segments\n",
    "        debug['rerank_places'] = rerank_places\n",
    "        \n",
    "        past_key_values = None\n",
    "        hidden_states = []\n",
    "        hidden_states_in_rerank_place = []\n",
    "        labels_in_rerank_place = []\n",
    "        all_rerank_hidden_states = []\n",
    "        all_rerank_labels = []\n",
    "        if not is_training:\n",
    "            no_rerank_logits = [] #no_rerank_labels is the same with all_rerank_labels, only need to be cal when eval\n",
    "        check_out_num = 0\n",
    "        for i in range(num_of_rerank+1):\n",
    "            #normal stage\n",
    "            segment_input_ids = input_ids[:, rerank_places[i]:rerank_places[i+1]]\n",
    "            segment_attention_masks = attention_mask[:, :rerank_places[i+1]]\n",
    "            \n",
    "            debug['segment_input_ids'] = segment_input_ids\n",
    "            debug['segment_attention_masks'] = segment_attention_masks\n",
    "\n",
    "            segment_outputs = self.transformer(\n",
    "                segment_input_ids,\n",
    "                attention_mask = segment_attention_masks,\n",
    "                past_key_values = past_key_values\n",
    "            )\n",
    "            \n",
    "            debug['segment_outputs'] = segment_outputs\n",
    "\n",
    "            segment_hidden = segment_outputs[0]\n",
    "            past_key_values = segment_outputs[1]\n",
    "\n",
    "            hidden_states.append(segment_hidden)\n",
    "\n",
    "            #rerank stage (just for rerank places)\n",
    "            if i == num_of_rerank:\n",
    "                break\n",
    "\n",
    "            #rerank stage\n",
    "            #get logits in rerank place\n",
    "            logits_before_rerank = self.lm_head(segment_hidden[:, -1, :])\n",
    "            #get candidate token ids according to the logits\n",
    "            candidate_token_logits, candidate_token_ids = torch.topk(logits_before_rerank, CAN_NUM)\n",
    "            rerank_labels = labels[..., rerank_places[i+1]]\n",
    "            labels_in_rerank_place.append(rerank_labels)\n",
    "            hidden_states_in_rerank_place.append(segment_hidden[:, -1, :])\n",
    "\n",
    "            debug['candidate_token_ids'] = candidate_token_ids\n",
    "            debug['rerank_labels'] = rerank_labels\n",
    "            \n",
    "            #check whether or not label in candidates\n",
    "            check_labels = rerank_labels.tolist()\n",
    "            check_candidates = candidate_token_ids.tolist()\n",
    "            \n",
    "            assert len(check_labels)==len(check_candidates)\n",
    "            \n",
    "            \n",
    "            #when training, check whether or not label in candidates, if not we add label into candidates\n",
    "            if is_training:\n",
    "                #check every data in batch\n",
    "                rerank_labels_this_place = []\n",
    "                for j in range(len(check_labels)):\n",
    "                    if check_labels[j] not in check_candidates[j]:\n",
    "                        check_out_num+=1\n",
    "                        replace_index = np.random.randint(CAN_NUM)\n",
    "                        candidate_token_ids[j][replace_index] = check_labels[j]\n",
    "                        rerank_labels_this_place.append(replace_index)          \n",
    "                    else:\n",
    "                        rerank_labels_this_place.append(check_candidates[j].index(check_labels[j]))\n",
    "                all_rerank_labels.append(torch.tensor(rerank_labels_this_place, device=device))\n",
    "            #when eval, check whether or not label in candidates, if not we do not do rerank\n",
    "            else:\n",
    "                rerank_labels = []\n",
    "                check_in_index = []\n",
    "\n",
    "                for j in range(len(check_labels)): \n",
    "                    if check_labels[j] in check_candidates[j]:\n",
    "                        rerank_labels.append(check_candidates[j].index(check_labels[j]))\n",
    "                        check_in_index.append(j)\n",
    "                    else:\n",
    "                        check_out_num+=1\n",
    "                rerank_labels = torch.tensor(rerank_labels, device=device)\n",
    "                    \n",
    "                if rerank_labels.shape[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    all_rerank_labels.append(rerank_labels)\n",
    "\n",
    "            #make context for rerank stage, 50256 is the token_id for </endoftext/>\n",
    "            sep_token = torch.ones(size = [candidate_token_ids.shape[0], 1], dtype = torch.long, device=device) * 50256\n",
    "            candidate_context_ids = torch.cat([sep_token, candidate_token_ids, sep_token, candidate_token_ids], -1)\n",
    "\n",
    "            #get output from gpt2\n",
    "            rerank_outputs = self.transformer(candidate_context_ids,\n",
    "                            past_key_values=past_key_values,\n",
    "                          )\n",
    "\n",
    "            #get rerank logits for candidates\n",
    "            rerank_hidden_states = rerank_outputs[0][:, 2+CAN_NUM:2+CAN_NUM*2]\n",
    "\n",
    "            if not is_training:\n",
    "                all_rerank_hidden_states.append(rerank_hidden_states[check_in_index])\n",
    "                no_rerank_logits.append(candidate_token_logits[check_in_index])\n",
    "            else:\n",
    "                all_rerank_hidden_states.append(rerank_hidden_states)\n",
    "        \n",
    "        # cal loss, loss = normal loss + rerank loss\n",
    "        loss = None\n",
    "\n",
    "        # cal normal loss\n",
    "        normal_loss = None\n",
    "        \n",
    "        hidden_states = torch.cat(hidden_states, 1)\n",
    "        lm_logits = self.lm_head(hidden_states)\n",
    "\n",
    "        # Shift so that tokens < n predict n\n",
    "        shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        # Flatten the tokens\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        normal_loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "        \n",
    "        # cal rerank loss\n",
    "        rerank_loss = None\n",
    "        \n",
    "        all_rerank_hidden_states = torch.cat(all_rerank_hidden_states, 0)\n",
    "        all_rerank_logits = self.rerank_linear_head(all_rerank_hidden_states)\n",
    "        all_rerank_logits = torch.reshape(all_rerank_logits, [-1, CAN_NUM])\n",
    "        all_rerank_labels = torch.cat(all_rerank_labels, 0)\n",
    "        \n",
    "        rerank_loss = loss_fct(all_rerank_logits, all_rerank_labels)\n",
    "        \n",
    "        #not sure which one to be used, loss is used to cal backward, others is for observation\n",
    "        #loss = rerank_loss\n",
    "        loss = normal_loss + rerank_loss\n",
    "        \n",
    "        # cal normal loss in rerank place (for comparision with rerank results), only evaluate\n",
    "        normal_loss_in_rerank_place = None\n",
    "        if not is_training:\n",
    "            no_rerank_logits = torch.cat(no_rerank_logits, 0)\n",
    "            no_rerank_logits = torch.reshape(no_rerank_logits, [-1, CAN_NUM])\n",
    "            #no_rerank_labels = torch.cat(all_rerank_labels, 0) #no_rerank_labels == all_rerank_labels\n",
    "\n",
    "            normal_loss_in_rerank_place = loss_fct(no_rerank_logits, all_rerank_labels)\n",
    "\n",
    "#             print(\"\\n batch info:\")\n",
    "#             print(\"there are \", check_out_num/(num_of_rerank*batch_size), \"labels not in candidates\")\n",
    "#             print(\"normal_loss_in_rerank_place\", normal_loss_in_rerank_place)\n",
    "#             print(\"rerank_loss\", rerank_loss)\n",
    "        \n",
    "#         # cal normal loss in rerank place (for comparision with rerank results)        \n",
    "#         normal_loss_in_rerank_place = None\n",
    "\n",
    "#         hidden_states_in_rerank_place = torch.cat(hidden_states_in_rerank_place, 0)\n",
    "#         lm_logits_in_rerank_place = self.lm_head(hidden_states_in_rerank_place)\n",
    "#         lm_logits_in_rerank_place = torch.reshape(lm_logits_in_rerank_place, [-1, VOCAB_SIZE])\n",
    "#         labels_in_rerank_place = torch.cat(labels_in_rerank_place, 0)\n",
    "        \n",
    "#         normal_loss_in_rerank_place = loss_fct(lm_logits_in_rerank_place, labels_in_rerank_place)\n",
    "        \n",
    "        if is_training:\n",
    "            model.train()\n",
    "        \n",
    "        return {\"loss\": loss,\n",
    "                \"normal_loss\": normal_loss,\n",
    "                \"normal_loss_in_rerank_place\": normal_loss_in_rerank_place,\n",
    "                \"rerank_loss\": rerank_loss,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/wiki2021/wiki2021_0to4.csv')\n",
    "train_df = train_df.sample(frac=1)\n",
    "validation_df = train_df.iloc[:100000]\n",
    "inside_validation_df = train_df.iloc[100000:110000]\n",
    "train_df =train_df.iloc[110000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iAYlS40Z3l-v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
      "The beginning of sequence token <|endoftext|> token has the id 50256\n",
      "The end of sequence token <|endoftext|> has the id 50256\n",
      "The padding token <|endoftext|> has the id 50256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of myGPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['rerank_linear_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the GPT tokenizer.\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token='<|endoftext|>') #gpt2-medium\n",
    "\n",
    "\n",
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))\n",
    "\n",
    "# instantiate the model\n",
    "model = myGPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "model.cuda()\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "    \n",
    "        for txt in txt_list:\n",
    "            #encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            encodings_dict = tokenizer('<|endoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            debug['encodings_dict'] = encodings_dict\n",
    "\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GPT2Dataset(train_df['text'], tokenizer, max_length=MAX_LEN)\n",
    "validation_dataset = GPT2Dataset(validation_df['text'], tokenizer, max_length=MAX_LEN)\n",
    "inside_validation_dataset = GPT2Dataset(inside_validation_df['text'], tokenizer, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [50256, 287, 1703, 354, 270, 4914, 11, 12926, 13, 40700, 1359, 428, 47872, 1621, 379, 262, 4082, 286, 262, 3660, 6142, 3356, 290, 351, 1895, 284, 10092, 15424, 9640, 29587, 329, 625, 2319, 812, 11, 262, 2646, 19788, 319, 34286, 12, 11718, 5199, 9055, 290, 465, 636, 287, 262, 6282, 286, 262, 3298, 4009, 356, 783, 760, 355, 42793, 13, 44909, 1522, 416, 262, 1936, 3173, 286, 12352, 422, 9055, 338, 19336, 13, 26362, 290, 7124, 13, 464, 11648, 717, 44119, 379, 262, 1853, 3309, 590, 13741, 11117, 11, 5442, 262, 2159, 31535, 16854, 560, 6093, 48705, 11289, 329, 39883, 290, 262, 15518, 45470, 11289, 13, 317, 717, 12268, 373, 2716, 319, 2901, 1542, 11, 1853, 13, 2202, 2693, 860, 11, 1853, 11, 17741, 4803, 32862, 262, 11648], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug['encodings_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            validation_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(validation_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "# For inside_validation the order doesn't matter, so we'll just read them sequentially.\n",
    "inside_validation_dataloader = DataLoader(\n",
    "            inside_validation_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(inside_validation_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate,\n",
    "                  eps = epsilon\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch 1,000  of  48,929. Loss: 4.907516956329346.   Elapsed: 0:38:15.\n",
      "  inside Validation Loss: 4.90\n",
      "  Average inside Validation normal_loss: 3.71\n",
      "  Average inside Validation normal_loss_in_rerank_place: 1.01\n",
      "  Average inside Validation rerank_loss: 1.18\n",
      "  inside Validation took: 0:03:52\n",
      "  Batch 2,000  of  48,929. Loss: 4.706604480743408.   Elapsed: 1:20:20.\n",
      "  inside Validation Loss: 4.84\n",
      "  Average inside Validation normal_loss: 3.69\n",
      "  Average inside Validation normal_loss_in_rerank_place: 1.00\n",
      "  Average inside Validation rerank_loss: 1.16\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 3,000  of  48,929. Loss: 4.863150596618652.   Elapsed: 2:02:18.\n",
      "  inside Validation Loss: 4.84\n",
      "  Average inside Validation normal_loss: 3.66\n",
      "  Average inside Validation normal_loss_in_rerank_place: 1.00\n",
      "  Average inside Validation rerank_loss: 1.17\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 4,000  of  48,929. Loss: 4.592685222625732.   Elapsed: 2:44:18.\n",
      "  inside Validation Loss: 4.80\n",
      "  Average inside Validation normal_loss: 3.66\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.99\n",
      "  Average inside Validation rerank_loss: 1.15\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 5,000  of  48,929. Loss: 4.627286434173584.   Elapsed: 3:26:16.\n",
      "  inside Validation Loss: 4.79\n",
      "  Average inside Validation normal_loss: 3.64\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.99\n",
      "  Average inside Validation rerank_loss: 1.15\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 6,000  of  48,929. Loss: 4.51023006439209.   Elapsed: 4:08:24.\n",
      "  inside Validation Loss: 4.78\n",
      "  Average inside Validation normal_loss: 3.63\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.99\n",
      "  Average inside Validation rerank_loss: 1.15\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 7,000  of  48,929. Loss: 4.720897674560547.   Elapsed: 4:50:27.\n",
      "  inside Validation Loss: 4.81\n",
      "  Average inside Validation normal_loss: 3.63\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.99\n",
      "  Average inside Validation rerank_loss: 1.18\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 8,000  of  48,929. Loss: 4.557641983032227.   Elapsed: 5:32:19.\n",
      "  inside Validation Loss: 4.75\n",
      "  Average inside Validation normal_loss: 3.61\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.99\n",
      "  Average inside Validation rerank_loss: 1.14\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 9,000  of  48,929. Loss: 4.7408881187438965.   Elapsed: 6:14:13.\n",
      "  inside Validation Loss: 4.73\n",
      "  Average inside Validation normal_loss: 3.60\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.99\n",
      "  Average inside Validation rerank_loss: 1.13\n",
      "  inside Validation took: 0:03:52\n",
      "  Batch 10,000  of  48,929. Loss: 4.34223747253418.   Elapsed: 6:56:17.\n",
      "  inside Validation Loss: 4.72\n",
      "  Average inside Validation normal_loss: 3.59\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.98\n",
      "  Average inside Validation rerank_loss: 1.12\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 11,000  of  48,929. Loss: 4.660743713378906.   Elapsed: 7:38:17.\n",
      "  inside Validation Loss: 4.72\n",
      "  Average inside Validation normal_loss: 3.59\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.99\n",
      "  Average inside Validation rerank_loss: 1.13\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 12,000  of  48,929. Loss: 4.543644905090332.   Elapsed: 8:20:27.\n",
      "  inside Validation Loss: 4.70\n",
      "  Average inside Validation normal_loss: 3.58\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.98\n",
      "  Average inside Validation rerank_loss: 1.12\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 13,000  of  48,929. Loss: 4.567580699920654.   Elapsed: 9:02:23.\n",
      "  inside Validation Loss: 4.70\n",
      "  Average inside Validation normal_loss: 3.57\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.98\n",
      "  Average inside Validation rerank_loss: 1.13\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 14,000  of  48,929. Loss: 4.4125142097473145.   Elapsed: 9:44:22.\n",
      "  inside Validation Loss: 4.69\n",
      "  Average inside Validation normal_loss: 3.57\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.98\n",
      "  Average inside Validation rerank_loss: 1.12\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 15,000  of  48,929. Loss: 4.7240495681762695.   Elapsed: 10:26:27.\n",
      "  inside Validation Loss: 4.69\n",
      "  Average inside Validation normal_loss: 3.57\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.98\n",
      "  Average inside Validation rerank_loss: 1.12\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 16,000  of  48,929. Loss: 4.640413761138916.   Elapsed: 11:08:44.\n",
      "  inside Validation Loss: 4.66\n",
      "  Average inside Validation normal_loss: 3.56\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.98\n",
      "  Average inside Validation rerank_loss: 1.10\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 17,000  of  48,929. Loss: 4.6924662590026855.   Elapsed: 11:50:51.\n",
      "  inside Validation Loss: 4.63\n",
      "  Average inside Validation normal_loss: 3.55\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 18,000  of  48,929. Loss: 4.5695695877075195.   Elapsed: 12:33:03.\n",
      "  inside Validation Loss: 4.66\n",
      "  Average inside Validation normal_loss: 3.55\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.11\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 19,000  of  48,929. Loss: 4.365029335021973.   Elapsed: 13:15:07.\n",
      "  inside Validation Loss: 4.66\n",
      "  Average inside Validation normal_loss: 3.55\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.98\n",
      "  Average inside Validation rerank_loss: 1.11\n",
      "  inside Validation took: 0:03:52\n",
      "  Batch 20,000  of  48,929. Loss: 4.484968185424805.   Elapsed: 13:57:19.\n",
      "  inside Validation Loss: 4.62\n",
      "  Average inside Validation normal_loss: 3.54\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 21,000  of  48,929. Loss: 4.396222114562988.   Elapsed: 14:39:28.\n",
      "  inside Validation Loss: 4.62\n",
      "  Average inside Validation normal_loss: 3.53\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.98\n",
      "  Average inside Validation rerank_loss: 1.09\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 22,000  of  48,929. Loss: 4.663304328918457.   Elapsed: 15:21:17.\n",
      "  inside Validation Loss: 4.61\n",
      "  Average inside Validation normal_loss: 3.53\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 23,000  of  48,929. Loss: 4.552908897399902.   Elapsed: 16:02:47.\n",
      "  inside Validation Loss: 4.61\n",
      "  Average inside Validation normal_loss: 3.53\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 24,000  of  48,929. Loss: 4.530828952789307.   Elapsed: 16:44:24.\n",
      "  inside Validation Loss: 4.62\n",
      "  Average inside Validation normal_loss: 3.52\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.10\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 25,000  of  48,929. Loss: 4.422646522521973.   Elapsed: 17:25:56.\n",
      "  inside Validation Loss: 4.61\n",
      "  Average inside Validation normal_loss: 3.52\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.09\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 26,000  of  48,929. Loss: 4.579982280731201.   Elapsed: 18:07:31.\n",
      "  inside Validation Loss: 4.61\n",
      "  Average inside Validation normal_loss: 3.51\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.10\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 27,000  of  48,929. Loss: 4.711855888366699.   Elapsed: 18:49:04.\n",
      "  inside Validation Loss: 4.61\n",
      "  Average inside Validation normal_loss: 3.51\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.10\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 28,000  of  48,929. Loss: 4.697641849517822.   Elapsed: 19:30:36.\n",
      "  inside Validation Loss: 4.59\n",
      "  Average inside Validation normal_loss: 3.50\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 29,000  of  48,929. Loss: 4.401515960693359.   Elapsed: 20:12:10.\n",
      "  inside Validation Loss: 4.58\n",
      "  Average inside Validation normal_loss: 3.50\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.09\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 30,000  of  48,929. Loss: 4.461573123931885.   Elapsed: 20:53:42.\n",
      "  inside Validation Loss: 4.59\n",
      "  Average inside Validation normal_loss: 3.50\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.09\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 31,000  of  48,929. Loss: 4.443973064422607.   Elapsed: 21:35:14.\n",
      "  inside Validation Loss: 4.58\n",
      "  Average inside Validation normal_loss: 3.49\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.09\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 32,000  of  48,929. Loss: 4.610875606536865.   Elapsed: 22:16:44.\n",
      "  inside Validation Loss: 4.57\n",
      "  Average inside Validation normal_loss: 3.49\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:52\n",
      "  Batch 33,000  of  48,929. Loss: 4.493189811706543.   Elapsed: 22:58:20.\n",
      "  inside Validation Loss: 4.55\n",
      "  Average inside Validation normal_loss: 3.48\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.07\n",
      "  inside Validation took: 0:03:52\n",
      "  Batch 34,000  of  48,929. Loss: 4.403716087341309.   Elapsed: 23:39:53.\n",
      "  inside Validation Loss: 4.59\n",
      "  Average inside Validation normal_loss: 3.48\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.11\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 35,000  of  48,929. Loss: 4.628944396972656.   Elapsed: 1 day, 0:21:26.\n",
      "  inside Validation Loss: 4.55\n",
      "  Average inside Validation normal_loss: 3.48\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.07\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 36,000  of  48,929. Loss: 4.290599822998047.   Elapsed: 1 day, 1:02:55.\n",
      "  inside Validation Loss: 4.54\n",
      "  Average inside Validation normal_loss: 3.47\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.07\n",
      "  inside Validation took: 0:03:52\n",
      "  Batch 37,000  of  48,929. Loss: 4.5877227783203125.   Elapsed: 1 day, 1:44:37.\n",
      "  inside Validation Loss: 4.56\n",
      "  Average inside Validation normal_loss: 3.47\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.09\n",
      "  inside Validation took: 0:03:56\n",
      "  Batch 38,000  of  48,929. Loss: 4.359678745269775.   Elapsed: 1 day, 2:26:18.\n",
      "  inside Validation Loss: 4.55\n",
      "  Average inside Validation normal_loss: 3.47\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 39,000  of  48,929. Loss: 4.241458415985107.   Elapsed: 1 day, 3:07:41.\n",
      "  inside Validation Loss: 4.55\n",
      "  Average inside Validation normal_loss: 3.47\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 40,000  of  48,929. Loss: 4.190263748168945.   Elapsed: 1 day, 3:49:08.\n",
      "  inside Validation Loss: 4.54\n",
      "  Average inside Validation normal_loss: 3.46\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.08\n",
      "  inside Validation took: 0:03:51\n",
      "  Batch 41,000  of  48,929. Loss: 4.3022379875183105.   Elapsed: 1 day, 4:30:31.\n",
      "  inside Validation Loss: 4.53\n",
      "  Average inside Validation normal_loss: 3.46\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.07\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 42,000  of  48,929. Loss: 4.330255508422852.   Elapsed: 1 day, 5:11:52.\n",
      "  inside Validation Loss: 4.53\n",
      "  Average inside Validation normal_loss: 3.46\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.96\n",
      "  Average inside Validation rerank_loss: 1.07\n",
      "  inside Validation took: 0:03:50\n",
      "  Batch 43,000  of  48,929. Loss: 4.271562099456787.   Elapsed: 1 day, 5:53:03.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7d90e3a38aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                     outputs  = model(b_input_ids, \n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;31m#                            token_type_ids=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                                      \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LM/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a7d800d62203>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, is_training)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m#get output from gpt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             rerank_outputs = self.transformer(candidate_context_ids,\n\u001b[0m\u001b[1;32m    144\u001b[0m                             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                           )\n",
      "\u001b[0;32m~/anaconda3/envs/LM/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/work1/llcao/zonghaiyao/LM/transformers/src/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    745\u001b[0m                 )\n\u001b[1;32m    746\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    748\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LM/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/work1/llcao/zonghaiyao/LM/transformers/src/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     ):\n\u001b[0;32m--> 289\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LM/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/work1/llcao/zonghaiyao/LM/transformers/src/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresid_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LM/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/work1/llcao/zonghaiyao/LM/transformers/src/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_t0 = time.time()\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_train_normal_loss = 0\n",
    "    total_train_normal_loss_in_rerank_place = 0\n",
    "    total_train_rerank_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None,\n",
    "                          is_training=True,\n",
    "                        )\n",
    "\n",
    "        debug['outputs'] = outputs\n",
    "\n",
    "        loss = outputs[\"loss\"]\n",
    "        normal_loss = outputs[\"normal_loss\"]\n",
    "        rerank_loss = outputs[\"rerank_loss\"]\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "        \n",
    "        batch_normal_loss = normal_loss.item()\n",
    "        total_train_normal_loss += batch_normal_loss\n",
    "        \n",
    "        batch_rerank_loss = rerank_loss.item()\n",
    "        total_train_rerank_loss += batch_rerank_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "            \n",
    "            t1 = time.time()\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            total_eval_loss = 0\n",
    "            total_eval_normal_loss = 0\n",
    "            total_eval_normal_loss_in_rerank_place = 0\n",
    "            total_eval_rerank_loss = 0\n",
    "\n",
    "            # Evaluate data for one epoch\n",
    "            for batch in inside_validation_dataloader:        \n",
    "                b_input_ids = batch[0].to(device)\n",
    "                b_labels = batch[0].to(device)\n",
    "                b_masks = batch[1].to(device)\n",
    "\n",
    "                with torch.no_grad():        \n",
    "\n",
    "                    outputs  = model(b_input_ids, \n",
    "        #                            token_type_ids=None, \n",
    "                                     attention_mask = b_masks,\n",
    "                                     labels=b_labels,\n",
    "                                     is_training=False,)\n",
    "\n",
    "                    loss = outputs[\"loss\"]\n",
    "                    normal_loss = outputs[\"normal_loss\"]\n",
    "                    normal_loss_in_rerank_place = outputs[\"normal_loss_in_rerank_place\"]\n",
    "                    rerank_loss = outputs[\"rerank_loss\"]\n",
    "\n",
    "                batch_loss = loss.item()\n",
    "                total_eval_loss += batch_loss        \n",
    "\n",
    "                batch_normal_loss = normal_loss.item()\n",
    "                total_eval_normal_loss += batch_normal_loss\n",
    "\n",
    "                batch_normal_loss_in_rerank_place = normal_loss_in_rerank_place.item()\n",
    "                total_eval_normal_loss_in_rerank_place += batch_normal_loss_in_rerank_place\n",
    "\n",
    "                batch_rerank_loss = rerank_loss.item()\n",
    "                total_eval_rerank_loss += batch_rerank_loss\n",
    "\n",
    "            avg_val_loss = total_eval_loss / len(inside_validation_dataloader)\n",
    "            avg_val_normal_loss = total_eval_normal_loss / len(inside_validation_dataloader)       \n",
    "            avg_val_normal_loss_in_rerank_place = total_eval_normal_loss_in_rerank_place / len(inside_validation_dataloader)       \n",
    "            avg_val_rerank_loss = total_eval_rerank_loss / len(inside_validation_dataloader)    \n",
    "\n",
    "            validation_time = format_time(time.time() - t1)    \n",
    "\n",
    "            print(\"  inside Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "            print(\"  Average inside Validation normal_loss: {0:.2f}\".format(avg_val_normal_loss))\n",
    "            print(\"  Average inside Validation normal_loss_in_rerank_place: {0:.2f}\".format(avg_val_normal_loss_in_rerank_place))\n",
    "            print(\"  Average inside Validation rerank_loss: {0:.2f}\".format(avg_val_rerank_loss))\n",
    "            print(\"  inside Validation took: {:}\".format(validation_time))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    avg_train_normal_loss = total_train_normal_loss / len(train_dataloader)      \n",
    "    avg_train_rerank_loss = total_train_rerank_loss / len(train_dataloader)       \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Average training normal_loss: {0:.2f}\".format(avg_train_normal_loss))\n",
    "    print(\"  Average training rerank_loss: {0:.2f}\".format(avg_train_rerank_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    total_eval_normal_loss = 0\n",
    "    total_eval_normal_loss_in_rerank_place = 0\n",
    "    total_eval_rerank_loss = 0\n",
    "\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids, \n",
    "#                            token_type_ids=None, \n",
    "                             attention_mask = b_masks,\n",
    "                             labels=b_labels,\n",
    "                             is_training=False,)\n",
    "          \n",
    "            loss = outputs[\"loss\"]\n",
    "            normal_loss = outputs[\"normal_loss\"]\n",
    "            normal_loss_in_rerank_place = outputs[\"normal_loss_in_rerank_place\"]\n",
    "            rerank_loss = outputs[\"rerank_loss\"]\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "        \n",
    "        batch_normal_loss = normal_loss.item()\n",
    "        total_eval_normal_loss += batch_normal_loss\n",
    "        \n",
    "        batch_normal_loss_in_rerank_place = normal_loss_in_rerank_place.item()\n",
    "        total_eval_normal_loss_in_rerank_place += batch_normal_loss_in_rerank_place\n",
    "        \n",
    "        batch_rerank_loss = rerank_loss.item()\n",
    "        total_eval_rerank_loss += batch_rerank_loss\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    avg_val_normal_loss = total_eval_normal_loss / len(validation_dataloader)       \n",
    "    avg_val_normal_loss_in_rerank_place = total_eval_normal_loss_in_rerank_place / len(validation_dataloader)       \n",
    "    avg_val_rerank_loss = total_eval_rerank_loss / len(validation_dataloader)    \n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)    \n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Average Validation normal_loss: {0:.2f}\".format(avg_val_normal_loss))\n",
    "    print(\"  Average Validation normal_loss_in_rerank_place: {0:.2f}\".format(avg_val_normal_loss_in_rerank_place))\n",
    "    print(\"  Average Validation rerank_loss: {0:.2f}\".format(avg_val_rerank_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "# print(f\"Perplexity: {math.exp(eval_loss):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch 1,000  of  48,832. Loss: 4.53739070892334.   Elapsed: 0:38:13.\n",
      "  inside Validation Loss: 4.56\n",
      "  Average inside Validation normal_loss: 3.49\n",
      "  Average inside Validation normal_loss_in_rerank_place: 0.97\n",
      "  Average inside Validation rerank_loss: 1.07\n",
      "  inside Validation took: 0:03:52\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c05a656a2796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtotal_train_rerank_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_rerank_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LM/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LM/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_i in range(0, 1):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_train_normal_loss = 0\n",
    "    total_train_normal_loss_in_rerank_place = 0\n",
    "    total_train_rerank_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None,\n",
    "                          is_training=True,\n",
    "                        )\n",
    "\n",
    "        debug['outputs'] = outputs\n",
    "\n",
    "        loss = outputs[\"loss\"]\n",
    "        normal_loss = outputs[\"normal_loss\"]\n",
    "        rerank_loss = outputs[\"rerank_loss\"]\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "        \n",
    "        batch_normal_loss = normal_loss.item()\n",
    "        total_train_normal_loss += batch_normal_loss\n",
    "        \n",
    "        batch_rerank_loss = rerank_loss.item()\n",
    "        total_train_rerank_loss += batch_rerank_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "            \n",
    "            t1 = time.time()\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            total_eval_loss = 0\n",
    "            total_eval_normal_loss = 0\n",
    "            total_eval_normal_loss_in_rerank_place = 0\n",
    "            total_eval_rerank_loss = 0\n",
    "\n",
    "            # Evaluate data for one epoch\n",
    "            for batch in inside_validation_dataloader:        \n",
    "                b_input_ids = batch[0].to(device)\n",
    "                b_labels = batch[0].to(device)\n",
    "                b_masks = batch[1].to(device)\n",
    "\n",
    "                with torch.no_grad():        \n",
    "\n",
    "                    outputs  = model(b_input_ids, \n",
    "        #                            token_type_ids=None, \n",
    "                                     attention_mask = b_masks,\n",
    "                                     labels=b_labels,\n",
    "                                     is_training=False,)\n",
    "\n",
    "                    loss = outputs[\"loss\"]\n",
    "                    normal_loss = outputs[\"normal_loss\"]\n",
    "                    normal_loss_in_rerank_place = outputs[\"normal_loss_in_rerank_place\"]\n",
    "                    rerank_loss = outputs[\"rerank_loss\"]\n",
    "\n",
    "                batch_loss = loss.item()\n",
    "                total_eval_loss += batch_loss        \n",
    "\n",
    "                batch_normal_loss = normal_loss.item()\n",
    "                total_eval_normal_loss += batch_normal_loss\n",
    "\n",
    "                batch_normal_loss_in_rerank_place = normal_loss_in_rerank_place.item()\n",
    "                total_eval_normal_loss_in_rerank_place += batch_normal_loss_in_rerank_place\n",
    "\n",
    "                batch_rerank_loss = rerank_loss.item()\n",
    "                total_eval_rerank_loss += batch_rerank_loss\n",
    "\n",
    "            avg_val_loss = total_eval_loss / len(inside_validation_dataloader)\n",
    "            avg_val_normal_loss = total_eval_normal_loss / len(inside_validation_dataloader)       \n",
    "            avg_val_normal_loss_in_rerank_place = total_eval_normal_loss_in_rerank_place / len(inside_validation_dataloader)       \n",
    "            avg_val_rerank_loss = total_eval_rerank_loss / len(inside_validation_dataloader)    \n",
    "\n",
    "            validation_time = format_time(time.time() - t1)    \n",
    "\n",
    "            print(\"  inside Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "            print(\"  Average inside Validation normal_loss: {0:.2f}\".format(avg_val_normal_loss))\n",
    "            print(\"  Average inside Validation normal_loss_in_rerank_place: {0:.2f}\".format(avg_val_normal_loss_in_rerank_place))\n",
    "            print(\"  Average inside Validation rerank_loss: {0:.2f}\".format(avg_val_rerank_loss))\n",
    "            print(\"  inside Validation took: {:}\".format(validation_time))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    avg_train_normal_loss = total_train_normal_loss / len(train_dataloader)      \n",
    "    avg_train_rerank_loss = total_train_rerank_loss / len(train_dataloader)       \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Average training normal_loss: {0:.2f}\".format(avg_train_normal_loss))\n",
    "    print(\"  Average training rerank_loss: {0:.2f}\".format(avg_train_rerank_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    total_eval_normal_loss = 0\n",
    "    total_eval_normal_loss_in_rerank_place = 0\n",
    "    total_eval_rerank_loss = 0\n",
    "\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids, \n",
    "#                            token_type_ids=None, \n",
    "                             attention_mask = b_masks,\n",
    "                             labels=b_labels,\n",
    "                             is_training=False,)\n",
    "          \n",
    "            loss = outputs[\"loss\"]\n",
    "            normal_loss = outputs[\"normal_loss\"]\n",
    "            normal_loss_in_rerank_place = outputs[\"normal_loss_in_rerank_place\"]\n",
    "            rerank_loss = outputs[\"rerank_loss\"]\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "        \n",
    "        batch_normal_loss = normal_loss.item()\n",
    "        total_eval_normal_loss += batch_normal_loss\n",
    "        \n",
    "        batch_normal_loss_in_rerank_place = normal_loss_in_rerank_place.item()\n",
    "        total_eval_normal_loss_in_rerank_place += batch_normal_loss_in_rerank_place\n",
    "        \n",
    "        batch_rerank_loss = rerank_loss.item()\n",
    "        total_eval_rerank_loss += batch_rerank_loss\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    avg_val_normal_loss = total_eval_normal_loss / len(validation_dataloader)       \n",
    "    avg_val_normal_loss_in_rerank_place = total_eval_normal_loss_in_rerank_place / len(validation_dataloader)       \n",
    "    avg_val_rerank_loss = total_eval_rerank_loss / len(validation_dataloader)    \n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)    \n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Average Validation normal_loss: {0:.2f}\".format(avg_val_normal_loss))\n",
    "    print(\"  Average Validation normal_loss_in_rerank_place: {0:.2f}\".format(avg_val_normal_loss_in_rerank_place))\n",
    "    print(\"  Average Validation rerank_loss: {0:.2f}\".format(avg_val_rerank_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "# print(f\"Perplexity: {math.exp(eval_loss):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5916, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug['outputs']['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"results/baseline_wiki2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cases analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch = None\n",
    "for batch in validation_dataloader:\n",
    "    eval_batch = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(eval_batch[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "i = 0\n",
    "#48-->colour 50-->with\n",
    "predict_token_index = 50\n",
    "past_key_values=None\n",
    "#normal stage\n",
    "segment_input_ids = eval_batch[0][3][0:predict_token_index]\n",
    "labels = eval_batch[0][3][predict_token_index]\n",
    "segment_input_ids = torch.reshape(torch.cat([segment_input_ids, segment_input_ids], 0), [-1, predict_token_index])\n",
    "segment_input_ids = segment_input_ids.cuda()\n",
    "segment_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(eval_batch[0][3]), '\\n')\n",
    "print(tokenizer.decode(segment_input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_outputs = model.transformer(\n",
    "    segment_input_ids,\n",
    "    past_key_values = past_key_values\n",
    ")\n",
    "\n",
    "segment_hidden = segment_outputs[0]\n",
    "past_key_values = segment_outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_before_rerank = model.lm_head(segment_hidden[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(logits_before_rerank, CAN_NUM).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.functional.softmax(torch.topk(logits_before_rerank, CAN_NUM).values, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_token_ids = torch.topk(logits_before_rerank, CAN_NUM).indices\n",
    "for i in range(CAN_NUM):\n",
    "    print(tokenizer.decode(candidate_token_ids[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_labels = labels\n",
    "tokenizer.decode(rerank_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make context for rerank stage, 50256 is the token_id for </endoftext/>\n",
    "sep_token = torch.ones(size = [candidate_token_ids.shape[0], 1], dtype = torch.long, device=device) * 50256\n",
    "candidate_context_ids = torch.cat([sep_token, candidate_token_ids, sep_token, candidate_token_ids], -1)\n",
    "tokenizer.decode(candidate_context_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_outputs = model.transformer(candidate_context_ids,\n",
    "                past_key_values=past_key_values,\n",
    "              )\n",
    "\n",
    "rerank_hidden_states = rerank_outputs[0][:, 2+CAN_NUM:2+CAN_NUM*2]\n",
    "rerank_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rerank_linear_head(rerank_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.functional.softmax(model.rerank_linear_head(rerank_hidden_states), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Language Modeling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
