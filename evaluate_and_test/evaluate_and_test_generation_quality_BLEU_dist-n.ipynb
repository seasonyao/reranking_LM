{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mobile-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Optional, Tuple, Union, Any, collections\n",
    "import torch\n",
    "import copy \n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers.file_utils import (\n",
    "    WEIGHTS_NAME,\n",
    "    is_apex_available,\n",
    "    is_datasets_available,\n",
    "    is_in_notebook,\n",
    "    is_sagemaker_distributed_available,\n",
    "    is_torch_tpu_available,\n",
    ")\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    SequenceClassifierOutputWithPast,\n",
    ")\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Model\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import math\n",
    "import copy \n",
    "import random\n",
    "from packaging import version\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPT2Model\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import Trainer, TrainerState, TrainingArguments\n",
    "\n",
    "from transformers.utils import logging\n",
    "logger = logging.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "champion-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "MAX_LEN = 128\n",
    "CAN_NUM = 20\n",
    "gen_sent_len = 30\n",
    "num_sent_gen = 3\n",
    "readable_context = False\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "SAVE_PATH = \"/mnt/nfs/work1/llcao/zonghaiyao/LM/\"\n",
    "\n",
    "global debug\n",
    "debug = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wicked-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wiki2021_GPT2Dataset(Dataset):\n",
    "    def __init__(self, input_ids):\n",
    "        self.input_ids = input_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respiratory-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rerankGPT2LMHeadModel_generation_sent(GPT2LMHeadModel):\n",
    "    def __init__(self, config, MAX_LEN=None, CAN_NUM=None, num_of_rerank=None):\n",
    "        super().__init__(config)\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.CAN_NUM = CAN_NUM\n",
    "        self.num_of_rerank = num_of_rerank\n",
    "        self.VOCAB_SIZE = config.vocab_size\n",
    "        \n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.rerank_linear_head = nn.Linear(config.n_embd, 1, bias=False)\n",
    "\n",
    "        self.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empty-campbell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rerankGPT2LMHeadModel_generation_sent(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  (rerank_linear_head): Linear(in_features=768, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm not really doing anything with the config buheret\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token='<|endoftext|>') #gpt2-medium\n",
    "tokenizer_GPT2 = GPT2Tokenizer.from_pretrained('gpt2', pad_token='<|endoftext|>') #gpt2-medium\n",
    "\n",
    "\n",
    "model = rerankGPT2LMHeadModel_generation_sent.from_pretrained(SAVE_PATH + \"results/baseline_wiki2021/exclude_cases_label_not_in_candidates_canNUM20/120000\",\n",
    "                                                                                    config=configuration)\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weird-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(SAVE_PATH + 'data/wiki2021/wiki2021_0to4_train_dataset.pkl', 'rb') as f:\n",
    "#     train_input_ids = pickle.load(f)\n",
    "# with open(SAVE_PATH + 'data/wiki2021/wiki2021_0to4_validation_dataset.pkl', 'rb') as f:\n",
    "#     validation_input_ids = pickle.load(f)\n",
    "with open(SAVE_PATH + 'data/wiki2021/wiki2021_0to4_inside_validation_dataset.pkl', 'rb') as f:\n",
    "    inside_validation_input_ids = pickle.load(f)\n",
    "    \n",
    "# train_dataset = wiki2021_GPT2Dataset(train_input_ids)\n",
    "# validation_dataset = wiki2021_GPT2Dataset(validation_input_ids)\n",
    "inside_validation_dataset = wiki2021_GPT2Dataset(inside_validation_input_ids)\n",
    "\n",
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order. \n",
    "# train_dataloader = DataLoader(\n",
    "#             train_dataset,  # The training samples.\n",
    "#             sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "#             batch_size = batch_size # Trains with this batch size.\n",
    "#         )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "# validation_dataloader = DataLoader(\n",
    "#             validation_dataset, # The validation samples.\n",
    "#             sampler = SequentialSampler(validation_dataset), # Pull out batches sequentially.\n",
    "#             batch_size = batch_size # Evaluate with this batch size.\n",
    "#         )\n",
    "\n",
    "# For inside_validation the order doesn't matter, so we'll just read them sequentially.\n",
    "inside_validation_dataloader = DataLoader(\n",
    "            inside_validation_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(inside_validation_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gross-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
    "\n",
    "def top_k_logits(logits, k, filling_value=-1e10):\n",
    "    #modified from https://github.com/graykode/gpt-2-Pytorch/blob/master/GPT2/sample.py\n",
    "    if k == 0:\n",
    "        return logits\n",
    "    values, _ = torch.topk(logits, k)\n",
    "    min_values = values[:, -1].view(-1, 1).expand_as(logits)\n",
    "    return torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * filling_value, logits)\n",
    "\n",
    "def sample_seq(model, context, gen_sent_len, device, temperature=1, top_k = 40, sample=True):\n",
    "#def sample_seq(model_condition, context, insert_loc, future_emb_chosen_arr, gen_sent_len, device, temperature=1, top_k = 5, sample=True):\n",
    "    #modified from https://github.com/graykode/gpt-2-Pytorch/blob/master/GPT2/sample.py\n",
    "    prev = context\n",
    "    batch_size = prev.size(0)\n",
    "    output = torch.zeros((batch_size, 0), dtype=torch.long, device = device)\n",
    "    past = None\n",
    "    #sample = False\n",
    "    for i in range(gen_sent_len):\n",
    "        outputs = model.transformer(prev, past_key_values = past)\n",
    "        logits = outputs.last_hidden_state\n",
    "        past = outputs.past_key_values\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        logits = top_k_logits(logits, k=top_k)\n",
    "        \n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        if sample:\n",
    "            if torch.isnan(probs).sum() > 0:\n",
    "                print(past)\n",
    "                print(prev)\n",
    "                print(insert_loc)\n",
    "                print(future_emb_chosen_arr)\n",
    "                print(logits)\n",
    "                print(probs)\n",
    "                sys.exit(0)\n",
    "            prev = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            _, prev = torch.topk(probs, k=1, dim=-1)\n",
    "        output = torch.cat((output, prev), dim=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exclusive-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[232, 675, 191, 688, 258, 672, 496, 585,  30,  45, 559, 156, 124, 381,\n",
      "          28, 586, 664, 182, 705, 395, 395, 713, 197, 143, 531, 709, 158, 292,\n",
      "         320, 319],\n",
      "        [748, 322, 496, 159, 372, 177, 337, 610, 232, 148,  73, 620, 448, 430,\n",
      "         138, 378, 709, 190, 450, 658, 709, 530, 518, 680, 518, 734, 721, 319,\n",
      "         731, 633],\n",
      "        [530, 258, 534, 646, 165,  14, 165, 591, 138,  45, 138,  12, 242, 629,\n",
      "         138, 487, 232, 138, 731, 284, 580, 719, 279, 448, 709, 138, 544, 367,\n",
      "         435,  27],\n",
      "        [232, 277, 709, 442, 232, 709, 530, 374, 550, 442, 533, 564, 283, 759,\n",
      "         506, 277,  88, 634, 138, 107, 119, 215, 477, 461, 709, 629, 533,  20,\n",
      "         430, 706]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d59b6a6c2136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                            sample=True)\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in inside_validation_dataloader:   \n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():  \n",
    "        \n",
    "        output = sample_seq(model=model,\n",
    "                           context=batch[:, :20], \n",
    "                           gen_sent_len=30,\n",
    "                           device=device,\n",
    "                           temperature=1,\n",
    "                           top_k = 40, \n",
    "                           sample=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "talented-challenge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rerankGPT2LMHeadModel_generation_sent(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  (rerank_linear_head): Linear(in_features=768, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "useful-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_context(context, outf = None, shortest_context = 50, longest_context = 150):\n",
    "    bad_context = False\n",
    "    context = context.replace('â',\"'\").replace('â','-').replace('\\n',\" \")\n",
    "    if len(context.split()) < shortest_context:\n",
    "    #if len(context.split()) < 5:\n",
    "        if outf is not None:\n",
    "            outf.write(\"Skip due to short context\\n\")\n",
    "        bad_context = True\n",
    "    #if len(context.split()) > 50:\n",
    "    if len(context.split()) > longest_context:\n",
    "        if outf is not None:\n",
    "            outf.write(\"Skip due to long context\\n\")\n",
    "        bad_context = True\n",
    "    try:\n",
    "        context.encode('ascii', 'strict')\n",
    "    except:\n",
    "        if outf is not None:\n",
    "            outf.write(\"Skip due to special token\\n\")\n",
    "        bad_context = True\n",
    "    return context, bad_context\n",
    "\n",
    "def get_word_list_spacy(inner_idx_tensor, feature_text, tokenizer_GPT2, nlp):\n",
    "    def get_word_list_from_text(feature_text_i):\n",
    "        feature_text_i_str = tokenizer_GPT2.convert_tokens_to_string(feature_text_i)\n",
    "        tokens = nlp.tokenizer(feature_text_i_str)\n",
    "        word_raw_list_i_j = []\n",
    "\n",
    "        for tok in tokens:\n",
    "            w = tok.text\n",
    "            word_raw_list_i_j.append(w)\n",
    "            \n",
    "        return word_raw_list_i_j\n",
    "    word_raw_list = []\n",
    "    word_raw_rest_list = []\n",
    "    batch_size, num_head = inner_idx_tensor.size()\n",
    "    inner_idx_tensor_np = inner_idx_tensor.cpu().numpy()\n",
    "    for b, feature_text_i in enumerate(feature_text):\n",
    "        word_raw_list_i = []\n",
    "        word_raw_rest_list_i = []\n",
    "        for j in range(num_head):\n",
    "            end_idx = inner_idx_tensor_np[b,j]\n",
    "            word_raw_list_i_j = get_word_list_from_text(feature_text_i[:end_idx])\n",
    "            #assert len(word_idx_list_i_j) > 0, print(feature_text_i[:end_idx])\n",
    "            word_raw_list_i.append(word_raw_list_i_j)\n",
    "            if end_idx == len(feature_text_i):\n",
    "                word_raw_rest_list_i.append([])\n",
    "            else:\n",
    "                word_raw_rest_list_i_j = get_word_list_from_text(feature_text_i[end_idx:])\n",
    "                word_raw_rest_list_i.append(word_raw_rest_list_i_j)\n",
    "            #count = word_idx_d2_count.get(w_idx,0)\n",
    "            #word_idx_d2_count[w_idx] += 1\n",
    "        word_raw_list.append(word_raw_list_i)\n",
    "        word_raw_rest_list.append(word_raw_rest_list_i)\n",
    "    return word_raw_list, word_raw_rest_list\n",
    "\n",
    "def print_eval_text(feature, i_batch, outf, tokenizer_GPT2, inner_idx_tensor, gen_sent_tensor, gen_sent_tensor_org, result_stats, word_raw_list, word_raw_rest_list, readable_context, run_eval):\n",
    "    #batch_size, num_head, top_k, n_basis = top_index.size()\n",
    "    #num_sent_gen = gen_sent_tensor.size(2)\n",
    "    batch_size, num_head, num_sent_gen, gen_sent_len = gen_sent_tensor.size()\n",
    "    \n",
    "    #not_ascii_multi = 0\n",
    "    #not_ascii_org = 0\n",
    "    for i_sent in range(batch_size):\n",
    "        outf.write('batch number: ' + str(i_sent) + '\\n')\n",
    "        last_end = -1\n",
    "        # for m in range(1):\n",
    "        for m in range(num_head):\n",
    "            outf.write('number of head: ' + str(m) + '\\n')\n",
    "            end = inner_idx_tensor[i_sent,m].item()\n",
    "            if end == last_end:\n",
    "                continue\n",
    "            last_end = end\n",
    "            \n",
    "            #outf.write(tokenizer_GPT2.convert_tokens_to_string(feature_text[i_sent][:end])+'\\n')\n",
    "            context = tokenizer_GPT2.decode(feature[i_sent,:end])\n",
    "            \n",
    "            if readable_context:\n",
    "                context, bad_context = preprocessing_context(context, outf)\n",
    "                if bad_context:\n",
    "                    continue\n",
    "\n",
    "            outf.write(context+'\\n')\n",
    "            outf.write('\\n')\n",
    "            \n",
    "            multi_sent_list = []\n",
    "            org_sent_list = []\n",
    "            for j in range(num_sent_gen):\n",
    "                print(gen_sent_tensor)\n",
    "                generated_sent = tokenizer_GPT2.decode(gen_sent_tensor[i_sent, m, j, :])\n",
    "                multi_sent_list.append(generated_sent)\n",
    "                if gen_sent_tensor_org.size(0) > 0:\n",
    "                    generated_sent_org = tokenizer_GPT2.decode( gen_sent_tensor_org[i_sent, m, j, :] )\n",
    "                    org_sent_list.append(generated_sent_org)\n",
    "\n",
    "            for j in range(num_sent_gen):\n",
    "                generated_sent = multi_sent_list[j]\n",
    "                print_sampled_sent(generated_sent, outf, 'multi-facet '+ str(j))\n",
    "                if run_eval:\n",
    "                    result_stats.update(\"Multi-facet\", gen_sent_tensor[i_sent, m, j, :], feature[i_sent,:end], tokenizer_GPT2, word_raw_list[i_sent][m], word_raw_rest_list[i_sent][m], m)\n",
    "            if run_eval:\n",
    "                result_stats.update_self_BLEU(\"Multi-facet\", m)\n",
    "            if gen_sent_tensor_org.size(0) > 0:\n",
    "                for j in range(num_sent_gen):\n",
    "                    \n",
    "                    generated_sent_org = org_sent_list[j]\n",
    "                    print_sampled_sent(generated_sent_org, outf, 'single-facet '+ str(j))\n",
    "                    if run_eval:\n",
    "                        result_stats.update(\"Single-facet\", gen_sent_tensor_org[i_sent, m, j, :], feature[i_sent,:end], tokenizer_GPT2, word_raw_list[i_sent][m], word_raw_rest_list[i_sent][m], m)\n",
    "                if run_eval:\n",
    "                    result_stats.update_self_BLEU(\"Single-facet\", m)\n",
    "\n",
    "            if run_eval:\n",
    "                result_stats.renew_ngram(m)\n",
    "    #outf.write('Number of not ascii code in multi: {}, in single: {}: {}\\n'.format(not_ascii_conditional, not_ascii_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-research",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "noble-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch0\n",
      "sent0\n",
      "head0\n",
      "head1\n",
      "head2\n",
      "sent1\n",
      "head0\n",
      "head1\n",
      "head2\n",
      "sent2\n",
      "head0\n",
      "head1\n",
      "head2\n",
      "sent3\n",
      "head0\n",
      "head1\n",
      "head2\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-849cdfcdfad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('generated.txt', 'w') as outf:\n",
    "    top_k = 5\n",
    "    nlp = English()\n",
    "    result_stats = []\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(inside_validation_dataloader):\n",
    "        sample_batched = sample_batched.to(device)\n",
    "        # if i_batch == 0:\n",
    "        #     continue\n",
    "        print(\"batch\"+str(i_batch))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        feature = sample_batched\n",
    "\n",
    "        feature_text = [ [tokenizer._convert_id_to_token(x) for x in feature[i,:].tolist()] for i in range(feature.size(0))]\n",
    "\n",
    "        max_prompt_len = MAX_LEN - gen_sent_len\n",
    "        min_prompt_len = 20\n",
    "        interval = gen_sent_len\n",
    "\n",
    "        batch_size = feature.size(0)\n",
    "        start_idx_list = list(range(min_prompt_len,max_prompt_len,interval))\n",
    "        num_head = len(start_idx_list)\n",
    "        inner_idx_tensor = torch.tensor(start_idx_list, dtype=torch.long, device = device)\n",
    "        inner_idx_tensor = inner_idx_tensor.expand(batch_size, num_head)\n",
    "        batch_size, num_head = inner_idx_tensor.size()\n",
    "\n",
    "        gen_sent_tensor = torch.empty( (batch_size, num_head, num_sent_gen, gen_sent_len), dtype=torch.long, device=device )\n",
    "        gen_sent_tensor_org = torch.empty( (batch_size, num_head, num_sent_gen, gen_sent_len), dtype=torch.long, device=device )\n",
    "\n",
    "        word_raw_list, word_raw_rest_list = get_word_list_spacy(inner_idx_tensor, feature_text, tokenizer_GPT2, nlp)\n",
    "\n",
    "        # for i_sent in range(1):\n",
    "        for i_sent in range(batch_size):\n",
    "            print(\"sent\"+str(i_sent))\n",
    "            last_end = -1\n",
    "\n",
    "            # for m in range(1):\n",
    "            for m in range(num_head):\n",
    "                print(\"head\"+str(m))\n",
    "\n",
    "                end = inner_idx_tensor[i_sent,m]\n",
    "                if end == last_end:\n",
    "                    continue\n",
    "                last_end = end\n",
    "\n",
    "                context = tokenizer_GPT2.convert_tokens_to_string(feature_text[i_sent][:end])\n",
    "                if readable_context:\n",
    "                    context_proc, bad_context = preprocessing_context(context, outf)\n",
    "                    if bad_context:\n",
    "                        continue\n",
    "\n",
    "                end_int = end.item()\n",
    "\n",
    "                start_int = 0\n",
    "                #if end_int > max_prompt_len:\n",
    "                #    start_int = end_int - max_prompt_len\n",
    "\n",
    "                t = time.time()\n",
    "                feature_expanded = feature[i_sent,start_int:end].unsqueeze(0).expand(num_sent_gen,end_int - start_int).to(device = device)\n",
    "                output_org = sample_seq(model, feature_expanded, gen_sent_len, device)\n",
    "                org_elapsed = time.time() - t\n",
    "                gen_sent_tensor_org[i_sent, m, :, :] = output_org\n",
    "\n",
    "\n",
    "#         print_eval_text(feature, i_batch, outf, tokenizer_GPT2, inner_idx_tensor, gen_sent_tensor, gen_sent_tensor_org, result_stats, word_raw_list, word_raw_rest_list,  readable_context, run_eval=False)\n",
    "        if i_batch + 1 >= batch_size:\n",
    "            break\n",
    "\n",
    "        assert 1==0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "loved-bacon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4667200735266074119, -4708381021269503468,  4524894602428591803,\n",
       "            ...,  4591375965241895367,  4468366343111550586,\n",
       "           -4757987309446062567],\n",
       "          [-4647638948083814628, -4786426570680665678,  4538538510920259206,\n",
       "            ...,  4650649286333604402, -4648216442934680226,\n",
       "            4612224125204042822],\n",
       "          [ 4617270926533810252, -4712863193305540103, -4621406999388471657,\n",
       "            ..., -4741785359233238129,  4470464840496527831,\n",
       "            4630079715142640538]],\n",
       "\n",
       "         [[-4631653489972325452,  4543991442222669136,  4593506146632195282,\n",
       "            ...,  4613749336794520314, -4640251318733179642,\n",
       "           -4715204684929366646],\n",
       "          [ 4529994732193020066,  4580012555543802580,  4545096719831721912,\n",
       "            ...,  4450257783891394026, -4594744705697561636,\n",
       "            4513010434334512339],\n",
       "          [ 4485396141847992375, -4655739133984832858,  4584038314280262893,\n",
       "            ..., -4804661371924284269, -4769281628169220899,\n",
       "           -4736031599814622694]],\n",
       "\n",
       "         [[-4716245982570366503,  4537038886561604300, -4664692027677086053,\n",
       "            ..., -4642343758078044123,  4544503275591949601,\n",
       "            4543452614946391983],\n",
       "          [-4638752531884737678, -4722886111539114301,  4632958425564313726,\n",
       "            ..., -4678857108995780864, -4732369064319664167,\n",
       "            4607916172054764848],\n",
       "          [-4686077786559026920,  4542751845914092363,  4413939886178349158,\n",
       "            ...,  4612602748043919050,  4536624802357234752,\n",
       "           -4715461165338632839]]],\n",
       "\n",
       "\n",
       "        [[[-4633067109729659032, -4631892919369940176,  4514476068293850680,\n",
       "            ...,  4598364937897193950, -4629109505680010058,\n",
       "            4540920031624348936],\n",
       "          [ 4589209089794399792,  4526297218491373641, -4642286935650571750,\n",
       "            ..., -4682043287538771924,  4593951723716590142,\n",
       "            4616177558853783781],\n",
       "          [-4639230222452279262, -4748605019945733153,  4606940681924477161,\n",
       "            ...,  4508149409693319574, -4709827768125800720,\n",
       "           -4649524256187528538]],\n",
       "\n",
       "         [[ 4632439327230364691, -4759532088904338279, -4635822045639875556,\n",
       "            ...,  4518636094184697907,  4535535914329423118,\n",
       "           -4697997912067666065],\n",
       "          [-4736568752062503664, -4635624146433754038,  4613391119338769480,\n",
       "            ..., -4814347485189067584,  4371781618903092232,\n",
       "            4479867196082221674],\n",
       "          [ 4610852855962380678,  4574252901289319088, -4644915850758912536,\n",
       "            ...,  4530314496801147472, -4716464587816118586,\n",
       "           -4656296876294665117]],\n",
       "\n",
       "         [[ 4626451045454183888,  4528756085123029881, -4718213711109477668,\n",
       "            ..., -4878943071769986686,  4485810973405837750,\n",
       "            4543018668619467319],\n",
       "          [ 4507897260750930623,  4599804847166488168,  4542490920222583979,\n",
       "            ...,  4650257830144053137,  4530590804947278816,\n",
       "            4525628674617881498],\n",
       "          [-4692815583052689704, -4820096829345385531,  4580705769701531335,\n",
       "            ...,  4572074178212306723,  4541217574078902172,\n",
       "            4615126337697889778]]],\n",
       "\n",
       "\n",
       "        [[[-4629105618746494516, -4695253653485933940, -4657092561935863506,\n",
       "            ...,  4595104389806703168,  4582626470493647984,\n",
       "            4578599021668114532],\n",
       "          [ 4543911048986481700,  4629165241454640142, -4631137741711604920,\n",
       "            ...,  4426112433368129148, -4692802846329266148,\n",
       "           -4614529453214157985],\n",
       "          [-4648401251077749194,  4597139880100954096, -4620236655141295592,\n",
       "            ..., -4668454994551374246,  4550926811500195882,\n",
       "            4566429358550001364]],\n",
       "\n",
       "         [[-4645184844561075182,  4524687857723555021, -4813944065349283496,\n",
       "            ..., -4659708613632430421, -4720944537208202535,\n",
       "           -4647566891428419950],\n",
       "          [ 4432326948258197298,  4568566626601811673, -4671526776675780010,\n",
       "            ...,  4584797331633427163,  4504243824135181733,\n",
       "           -4647213896641654692],\n",
       "          [-4747704083999401183,  4549727270054746112,  4524758505631451575,\n",
       "            ...,  4577796341668555811, -4659978283892806883,\n",
       "           -4641484322221094956]],\n",
       "\n",
       "         [[-4662719362091305188, -4631441539797918460,  4533746804886486340,\n",
       "            ..., -4650695160912652822,  4567280425631311406,\n",
       "           -4681625425881983262],\n",
       "          [ 4537243715735843526, -4812672645547868581, -4773572251124389008,\n",
       "            ...,  4555745412643705178,  4573101777047695347,\n",
       "            4550488082728913396],\n",
       "          [ 4604507458385410113,  4576878028261456752,  4539817681035348731,\n",
       "            ...,  4519485050303119886,  4577822684850916951,\n",
       "           -4730225845581480184]]],\n",
       "\n",
       "\n",
       "        [[[ 4602183438704493911,  4557417308104335347,  4602559598367979990,\n",
       "            ..., -4668986655663597262,  4540188128406885671,\n",
       "           -4868579968526136774],\n",
       "          [ 4608588132577731210,  4608180531585179620, -4637046892999240535,\n",
       "            ..., -4690040787224730093,  4621760183106315064,\n",
       "           -4718329658030879643],\n",
       "          [-4658322780150885862,  4634474716518868157,  4612446555122820483,\n",
       "            ...,  4615936044253163376,  4437374000841031044,\n",
       "            4464454134676455423]],\n",
       "\n",
       "         [[ 4591944943177939072, -4620965515397146307,  4423652357717076829,\n",
       "            ...,  4580503109519286581,  4523187413048519470,\n",
       "            4432544243549085195],\n",
       "          [ 4607650998643539526, -4705537233244820965,  4594422306084876572,\n",
       "            ..., -4665550752750437080, -4703128830340525167,\n",
       "           -4713895026999769053],\n",
       "          [ 4509187887688135159, -4647451086199466714,  4573620791630729742,\n",
       "            ...,  4614123336119009066, -4670917930683136550,\n",
       "           -4659878913384036384]],\n",
       "\n",
       "         [[-4607927027621358681, -4734003846984748931,  4613577967627424793,\n",
       "            ...,  4623495998446428485,  4553339655413478148,\n",
       "            4637222713925526424],\n",
       "          [ 4547481597042382995,  4599857108329507745,  4566145100424102530,\n",
       "            ..., -4616914734166938158,  4599329488779744245,\n",
       "            4620211931130057387],\n",
       "          [ 4562763275387559958,  4579474868572470659, -4634860076061331556,\n",
       "            ...,  4557115404132238678,  4595526024642771466,\n",
       "            4585501592445421892]]]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_sent_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_interactive_LM(model_multi, model_single, gpt2_model, device, num_sent_gen, gen_sent_len, dataloader, outf, max_batch_num, tokenizer_GPT2, bptt, readable_context = False, run_eval = True):\n",
    "    top_k = 5\n",
    "    nlp = English()\n",
    "\n",
    "    #emb_sum = torch.sum(word_norm_emb,dim=1)\n",
    "    #OOV_list = torch.nonzero(emb_sum == 0).squeeze().cpu().tolist()\n",
    "    #print(\"OOV number = {}\".format(len(OOV_list)))\n",
    "    #print(\"OOV index examples {}\".format(OOV_list[:10]))\n",
    "    #OOV_set = set(OOV_list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if run_eval:\n",
    "            result_stats = result_statistics(gpt2_model)\n",
    "            result_stats.add_model(\"Multi-facet\")\n",
    "            result_stats.add_model(\"Single-facet\")\n",
    "        else:\n",
    "            result_stats = []\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            # if i_batch == 0:\n",
    "            #     continue\n",
    "            print(\"batch\"+str(i_batch))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            feature = sample_batched\n",
    "            \n",
    "            feature_text = [ [tokenizer_GPT2._convert_id_to_token(x) for x in feature[i,:].tolist()] for i in range(feature.size(0))]\n",
    "\n",
    "            max_prompt_len = bptt - gen_sent_len\n",
    "            min_prompt_len = 20\n",
    "            interval = gen_sent_len\n",
    "            \n",
    "            batch_size = feature.size(0)\n",
    "            start_idx_list = list(range(min_prompt_len,max_prompt_len,interval))\n",
    "            num_head = len(start_idx_list)\n",
    "            inner_idx_tensor = torch.tensor(start_idx_list, dtype=torch.long, device = device)\n",
    "            inner_idx_tensor = inner_idx_tensor.expand(batch_size, num_head)\n",
    "            batch_size, num_head = inner_idx_tensor.size()\n",
    "\n",
    "            gen_sent_tensor = torch.empty( (batch_size, num_head, num_sent_gen, gen_sent_len), dtype=torch.long, device=device )\n",
    "            gen_sent_tensor_org = torch.empty( (batch_size, num_head, num_sent_gen, gen_sent_len), dtype=torch.long, device=device )\n",
    "\n",
    "            word_raw_list, word_raw_rest_list = get_word_list_spacy(inner_idx_tensor, feature_text, tokenizer_GPT2, nlp)\n",
    "            # for i_sent in range(1):\n",
    "            for i_sent in range(batch_size):\n",
    "                print(\"sent\"+str(i_sent))\n",
    "                last_end = -1\n",
    "                \n",
    "                # for m in range(1):\n",
    "                for m in range(num_head):\n",
    "                    print(\"head\"+str(m))\n",
    "\n",
    "                    end = inner_idx_tensor[i_sent,m]\n",
    "                    if end == last_end:\n",
    "                        continue\n",
    "                    last_end = end\n",
    "                    \n",
    "                    context = tokenizer_GPT2.convert_tokens_to_string(feature_text[i_sent][:end])\n",
    "                    if readable_context:\n",
    "                        context_proc, bad_context = preprocessing_context(context, outf)\n",
    "                        if bad_context:\n",
    "                            continue\n",
    "\n",
    "                    end_int = end.item()\n",
    "                    \n",
    "                    start_int = 0\n",
    "                    #if end_int > max_prompt_len:\n",
    "                    #    start_int = end_int - max_prompt_len\n",
    "                    \n",
    "                    t = time.time()\n",
    "                    feature_expanded = feature[i_sent,start_int:end].unsqueeze(0).expand(num_sent_gen,end_int - start_int).to(device = device)\n",
    "                    if model_multi.output_probs:\n",
    "                        output = sample_seq_prob(model_multi, feature_expanded, gen_sent_len, device)\n",
    "                    else:\n",
    "                        output = sample_seq(model_multi, feature_expanded, gen_sent_len, device)\n",
    "                    multi_elapsed = time.time() - t\n",
    "                    gen_sent_tensor[i_sent, m, :, :] = output\n",
    "                    \n",
    "                    t = time.time()\n",
    "                    if model_single.output_probs:\n",
    "                        output_org = sample_seq_prob(model_single, feature_expanded, gen_sent_len, device)\n",
    "                    else:\n",
    "                        output_org = sample_seq(model_single, feature_expanded, gen_sent_len, device)\n",
    "                    org_elapsed = time.time() - t\n",
    "                    gen_sent_tensor_org[i_sent, m, :, :] = output_org\n",
    "                    \n",
    "                    \n",
    "                    if run_eval:\n",
    "                        #result_stats.model_results[\"time_count\"] += 1\n",
    "                        for method_name, time_spent in [ (\"Multi-facet\",multi_elapsed), (\"Single-facet\", org_elapsed)]:\n",
    "                            result_stats.model_results[method_name][\"time_sum\"] += time_spent\n",
    "                            result_stats.model_results[method_name][\"time_count\"] += 1\n",
    "\n",
    "                \n",
    "            print_eval_text(feature, i_batch, outf, tokenizer_GPT2, inner_idx_tensor, gen_sent_tensor, gen_sent_tensor_org, result_stats, word_raw_list, word_raw_rest_list,  readable_context, run_eval)\n",
    "            if i_batch + 1 >= max_batch_num:\n",
    "                break\n",
    "        if run_eval:\n",
    "            result_stats.print()\n",
    "            result_stats.generate_report(outf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
