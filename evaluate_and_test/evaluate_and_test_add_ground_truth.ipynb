{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mobile-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Optional, Tuple, Union, Any, collections\n",
    "import torch\n",
    "import copy \n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers.file_utils import (\n",
    "    WEIGHTS_NAME,\n",
    "    is_apex_available,\n",
    "    is_datasets_available,\n",
    "    is_in_notebook,\n",
    "    is_sagemaker_distributed_available,\n",
    "    is_torch_tpu_available,\n",
    ")\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    SequenceClassifierOutputWithPast,\n",
    ")\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Model\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import math\n",
    "import copy \n",
    "import random\n",
    "from packaging import version\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, GPT2Model\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import Trainer, TrainerState, TrainingArguments\n",
    "\n",
    "from transformers.utils import logging\n",
    "logger = logging.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "champion-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "MAX_LEN = 128\n",
    "CAN_NUM = 20\n",
    "num_of_rerank = 30\n",
    "\n",
    "# some parameters I cooked up that work reasonably well\n",
    "epochs = 1\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 1e2\n",
    "epsilon = 1e-8\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "SAVE_PATH = \"/mnt/nfs/work1/llcao/zonghaiyao/LM/\"\n",
    "\n",
    "global debug\n",
    "debug = {}\n",
    "debug['check_in_num'] = 0\n",
    "debug['total_sample_num'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wicked-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wiki2021_GPT2Dataset(Dataset):\n",
    "    def __init__(self, input_ids):\n",
    "        self.input_ids = input_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respiratory-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rerankGPT2LMHeadModel_labelInCandidate(GPT2LMHeadModel):\n",
    "    def __init__(self, config, MAX_LEN, CAN_NUM, num_of_rerank):\n",
    "        super().__init__(config)\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.CAN_NUM = CAN_NUM\n",
    "        self.num_of_rerank = num_of_rerank\n",
    "        self.VOCAB_SIZE = config.vocab_size\n",
    "        \n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "#         self.rerank_transformer = GPT2Model(config)\n",
    "        self.rerank_linear_head = nn.Linear(config.n_embd, 1, bias=False)\n",
    "\n",
    "        self.init_weights()\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        labels=None,\n",
    "        is_training=False,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "            Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\n",
    "            ``labels = input_ids`` Indices are selected in ``[-100, 0, ..., config.vocab_size]`` All labels set to\n",
    "            ``-100`` are ignored (masked), the loss is only computed for labels in ``[0, ..., config.vocab_size]``\n",
    "        \"\"\"       \n",
    "        global debug\n",
    "        # rerank_places = random.sample(np.arange(1, MAX_LEN-2-CAN_NUM*2).tolist(), k=num_of_rerank) #no duplicate\n",
    "        rerank_places = random.sample(np.arange(1, self.MAX_LEN).tolist(), k=self.num_of_rerank) #no duplicate\n",
    "        rerank_places = np.concatenate(([0], np.sort(rerank_places), [self.MAX_LEN])) #add first and last tokens to make segments\n",
    "        \n",
    "        past_key_values = None\n",
    "        hidden_states_in_rerank_place = []\n",
    "        stage1_logits_in_rerank_place = []\n",
    "        all_rerank_hidden_states = []\n",
    "        all_rerank_labels = []\n",
    "        if not is_training:\n",
    "            no_rerank_logits = [] #no_rerank_labels is the same with all_rerank_labels, only need to be cal when eval\n",
    "        check_out_num = 0\n",
    "        for i in range(self.num_of_rerank+1):\n",
    "            #normal stage\n",
    "            segment_input_ids = input_ids[:, rerank_places[i]:rerank_places[i+1]]\n",
    "\n",
    "            segment_outputs = self.transformer(\n",
    "                segment_input_ids,\n",
    "                past_key_values = past_key_values\n",
    "            )\n",
    "\n",
    "            segment_hidden = segment_outputs[0]\n",
    "            past_key_values = segment_outputs[1]\n",
    "\n",
    "            #rerank stage (just for rerank places)\n",
    "            if i == self.num_of_rerank:\n",
    "                break\n",
    "\n",
    "            #rerank stage\n",
    "            #get logits in rerank place\n",
    "            logits_before_rerank = self.lm_head(segment_hidden[:, -1, :])\n",
    "            #get candidate token ids according to the logits\n",
    "            candidate_token_logits, candidate_token_ids = torch.topk(logits_before_rerank, self.CAN_NUM)\n",
    "            rerank_labels = labels[..., rerank_places[i+1]]\n",
    "#             labels_in_rerank_place.append(rerank_labels)\n",
    "#             hidden_states_in_rerank_place.append(segment_hidden[:, -1, :])\n",
    "\n",
    "            \n",
    "            #check whether or not label in candidates\n",
    "            check_labels = rerank_labels.tolist()\n",
    "            check_candidates = candidate_token_ids.tolist()\n",
    "            \n",
    "#             debug['logits_before_rerank'] = logits_before_rerank\n",
    "#             debug['check_labels'] = check_labels\n",
    "#             debug['check_candidates'] = check_candidates\n",
    "#             debug['candidate_token_logits'] = candidate_token_logits\n",
    "#             debug['candidate_token_ids'] = candidate_token_ids\n",
    "            \n",
    "            assert len(check_labels)==len(check_candidates)\n",
    "            \n",
    "            \n",
    "            #when training, check whether or not label in candidates, if not we add label into candidates\n",
    "            #check every data in batch\n",
    "            rerank_labels_this_place = []\n",
    "            for j in range(len(check_labels)):\n",
    "                if check_labels[j] not in check_candidates[j]:\n",
    "                    check_out_num+=1\n",
    "                    replace_index = np.random.randint(self.CAN_NUM)\n",
    "                    candidate_token_ids[j][replace_index] = check_labels[j]\n",
    "                    candidate_token_logits[j][replace_index] = logits_before_rerank[j][check_labels[j]]\n",
    "                    rerank_labels_this_place.append(replace_index)          \n",
    "                else:\n",
    "                    rerank_labels_this_place.append(check_candidates[j].index(check_labels[j]))\n",
    "            all_rerank_labels.append(torch.tensor(rerank_labels_this_place, device=input_ids.device))\n",
    "            stage1_logits_in_rerank_place.append(candidate_token_logits)\n",
    "\n",
    "            #make context for rerank stage, 50256 is the token_id for </endoftext/>\n",
    "            sep_token = torch.ones(size = [candidate_token_ids.shape[0], 1], dtype = torch.long, device=input_ids.device) * 50256\n",
    "            candidate_context_ids = torch.cat([sep_token, candidate_token_ids, sep_token, candidate_token_ids], -1)\n",
    "       \n",
    "            #get output from gpt2\n",
    "            rerank_outputs = self.transformer(candidate_context_ids,\n",
    "                            past_key_values=past_key_values,\n",
    "                          )\n",
    "\n",
    "            #get rerank logits for candidates\n",
    "            rerank_hidden_states = rerank_outputs[0][:, 2+self.CAN_NUM:2+self.CAN_NUM*2]\n",
    "\n",
    "            all_rerank_hidden_states.append(rerank_hidden_states)\n",
    "            \n",
    "\n",
    "#         print(\"\\n batch info:\")\n",
    "#         print(\"there are \", check_out_num/(self.num_of_rerank*batch_size), \"labels not in candidates\")\n",
    "        \n",
    "        #-------------------------------------------------------------------------\n",
    "        # cal loss, loss = normal loss + rerank loss\n",
    "        loss_fct = CrossEntropyLoss(reduction='none')\n",
    "        \n",
    "        debug['all_rerank_labels'] = all_rerank_labels\n",
    "        debug['hidden_states_in_rerank_place'] = hidden_states_in_rerank_place\n",
    "        \n",
    "        # cal rerank loss\n",
    "        rerank_loss = None\n",
    "        \n",
    "        all_rerank_hidden_states = torch.cat(all_rerank_hidden_states, 0)\n",
    "        all_rerank_logits = self.rerank_linear_head(all_rerank_hidden_states)\n",
    "        all_rerank_logits = torch.reshape(all_rerank_logits, [-1, self.CAN_NUM])\n",
    "        all_rerank_labels = torch.cat(all_rerank_labels, 0)\n",
    "        \n",
    "        rerank_loss = loss_fct(all_rerank_logits, all_rerank_labels)\n",
    "        \n",
    "\n",
    "        # cal normal loss in rerank place (for comparision with rerank results)        \n",
    "        normal_loss_in_rerank_place = None\n",
    "        \n",
    "        stage1_logits_in_rerank_place = torch.cat(stage1_logits_in_rerank_place, 0)        \n",
    "        normal_loss_in_rerank_place = loss_fct(stage1_logits_in_rerank_place, all_rerank_labels)\n",
    "        \n",
    "        \n",
    "        stage1_logits = stage1_logits_in_rerank_place.tolist()\n",
    "        stage2_logits = all_rerank_logits.tolist()\n",
    "        labels = all_rerank_labels.tolist()\n",
    "        \n",
    "        def cal_gt_value_rank_in_array(logits_array, ground_true_place):\n",
    "            \n",
    "            array = (-1) * np.array(logits_array) #for reverse ranking\n",
    "            temp = array.argsort()\n",
    "            ranks = np.empty_like(temp)\n",
    "            ranks[temp] = np.arange(len(array))\n",
    "            return ranks[ground_true_place]\n",
    "        ranks_stage1 = []\n",
    "        ranks_stage2 = []\n",
    "        for i in range(all_rerank_labels.shape[0]):\n",
    "            ranks_stage1.append(cal_gt_value_rank_in_array(stage1_logits[i], labels[i]))\n",
    "            ranks_stage2.append(cal_gt_value_rank_in_array(stage2_logits[i], labels[i]))\n",
    "            \n",
    "        debug['ranks_stage1'] = ranks_stage1\n",
    "        debug['ranks_stage2'] = ranks_stage2\n",
    "        \n",
    "        print(\"rerank_loss:\", rerank_loss[:5])\n",
    "        print(\"normal_loss:\", normal_loss_in_rerank_place[:5])\n",
    "        print(\"ranks_stage1:\", ranks_stage1[:5])\n",
    "        print(\"ranks_stage2:\", ranks_stage2[:5])\n",
    "\n",
    "#         hidden_states_in_rerank_place = torch.cat(hidden_states_in_rerank_place, 0)\n",
    "#         lm_logits_in_rerank_place = self.lm_head(hidden_states_in_rerank_place)\n",
    "#         lm_logits_in_rerank_place = torch.reshape(lm_logits_in_rerank_place, [-1, self.VOCAB_SIZE])\n",
    "#         labels_in_rerank_place = torch.cat(labels_in_rerank_place, 0)\n",
    "\n",
    "#         normal_loss_in_rerank_place = loss_fct(lm_logits_in_rerank_place, labels_in_rerank_place)\n",
    "        \n",
    "        return {\"normal_loss_in_rerank_place\": normal_loss_in_rerank_place,\n",
    "                \"rerank_loss\": rerank_loss,\n",
    "                \"ranks_stage1\": ranks_stage1,\n",
    "                \"ranks_stage2\": ranks_stage2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empty-campbell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): rerankGPT2LMHeadModel_labelInCandidate(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "    (rerank_linear_head): Linear(in_features=768, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm not really doing anything with the config buheret\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token='<|endoftext|>') #gpt2-medium\n",
    "\n",
    "# instantiate the model\n",
    "model = rerankGPT2LMHeadModel_labelInCandidate.from_pretrained(SAVE_PATH + \"results/baseline_wiki2021/exclude_cases_label_not_in_candidates_canNUM20/120000\", \n",
    "                                                                                    config=configuration,\n",
    "                                                                                    MAX_LEN = MAX_LEN,\n",
    "                                                                                    CAN_NUM = CAN_NUM, \n",
    "                                                                                   num_of_rerank = num_of_rerank)\n",
    "\n",
    "\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "model = torch.nn.DataParallel(model) # Encapsulate the model\n",
    "\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weird-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(SAVE_PATH + 'data/wiki2021/wiki2021_0to4_train_dataset.pkl', 'rb') as f:\n",
    "#     train_input_ids = pickle.load(f)\n",
    "with open(SAVE_PATH + 'data/wiki2021/wiki2021_0to4_validation_dataset.pkl', 'rb') as f:\n",
    "    validation_input_ids = pickle.load(f)\n",
    "with open(SAVE_PATH + 'data/wiki2021/wiki2021_0to4_inside_validation_dataset.pkl', 'rb') as f:\n",
    "    inside_validation_input_ids = pickle.load(f)\n",
    "    \n",
    "# train_dataset = wiki2021_GPT2Dataset(train_input_ids)\n",
    "validation_dataset = wiki2021_GPT2Dataset(validation_input_ids)\n",
    "inside_validation_dataset = wiki2021_GPT2Dataset(inside_validation_input_ids)\n",
    "\n",
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order. \n",
    "# train_dataloader = DataLoader(\n",
    "#             train_dataset,  # The training samples.\n",
    "#             sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "#             batch_size = batch_size # Trains with this batch size.\n",
    "#         )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            validation_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(validation_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "# For inside_validation the order doesn't matter, so we'll just read them sequentially.\n",
    "inside_validation_dataloader = DataLoader(\n",
    "            inside_validation_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(inside_validation_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gross-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exclusive-journalism",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "rerank_loss: tensor([1.4274, 4.1998, 1.5362, 4.2876, 4.6577], device='cuda:0')\n",
      "normal_loss: tensor([1.2354, 6.7931, 1.3189, 7.0454, 5.0614], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 0, 19, 19]\n",
      "ranks_stage2: [0, 11, 0, 16, 13]\n",
      "rerank_loss: tensor([4.4119, 1.7867, 2.2997, 5.6258, 1.0694], device='cuda:0')\n",
      "normal_loss: tensor([6.4540, 1.6272, 2.3816, 8.2732, 1.0126], device='cuda:0')\n",
      "ranks_stage1: [19, 1, 1, 19, 0]\n",
      "ranks_stage2: [10, 0, 2, 19, 0]\n",
      "rerank_loss: tensor([4.7456, 2.1354, 5.7403, 3.5086, 3.0893], device='cuda:0')\n",
      "normal_loss: tensor([7.2976, 5.9622, 5.1238, 3.1874, 3.2023], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 5, 6]\n",
      "ranks_stage2: [18, 0, 18, 6, 6]\n",
      "rerank_loss: tensor([3.5934, 4.5537, 4.3872, 2.4179, 1.0724], device='cuda:0')\n",
      "normal_loss: tensor([5.7373, 5.2250, 6.0206, 2.5663, 0.1460], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 4, 0]\n",
      "ranks_stage2: [11, 17, 17, 2, 0]\n",
      "rerank_loss: tensor([0.2390, 2.6041, 2.0155, 6.0171, 1.6813], device='cuda:0')\n",
      "normal_loss: tensor([0.1990, 2.0823, 4.7408, 6.8998, 2.0381], device='cuda:0')\n",
      "ranks_stage1: [0, 3, 19, 19, 1]\n",
      "ranks_stage2: [0, 3, 1, 18, 1]\n",
      "rerank_loss: tensor([3.5433e+00, 9.5041e-03, 5.2589e+00, 4.9989e+00, 3.8160e-03],\n",
      "       device='cuda:0')\n",
      "normal_loss: tensor([5.2021e+00, 3.1529e-03, 5.8711e+00, 6.2458e+00, 1.3077e-03],\n",
      "       device='cuda:0')\n",
      "ranks_stage1: [19, 0, 19, 19, 0]\n",
      "ranks_stage2: [10, 0, 13, 15, 0]\n",
      "rerank_loss: tensor([3.9732, 5.3268, 1.9213, 2.7865, 1.7431], device='cuda:0')\n",
      "normal_loss: tensor([3.8988, 6.5724, 6.1753, 7.0440, 1.8778], device='cuda:0')\n",
      "ranks_stage1: [18, 19, 19, 19, 1]\n",
      "ranks_stage2: [15, 18, 1, 7, 1]\n",
      "rerank_loss: tensor([4.8509, 0.2405, 0.3658, 5.3496, 3.7947], device='cuda:0')\n",
      "normal_loss: tensor([6.7723, 0.0685, 0.2398, 7.8021, 8.3987], device='cuda:0')\n",
      "ranks_stage1: [19, 0, 0, 19, 19]\n",
      "ranks_stage2: [11, 0, 0, 18, 11]\n",
      "rerank_loss: tensor([4.8397, 0.0951, 1.2188, 4.1002, 3.8972], device='cuda:0')\n",
      "normal_loss: tensor([5.1831, 0.0439, 0.9239, 4.2891, 5.2440], device='cuda:0')\n",
      "ranks_stage1: [15, 0, 1, 19, 19]\n",
      "ranks_stage2: [13, 0, 1, 17, 12]\n",
      "rerank_loss: tensor([3.1146, 4.8385, 4.8001, 3.6525, 3.4894], device='cuda:0')\n",
      "normal_loss: tensor([3.0347, 6.2039, 5.9789, 6.6626, 6.2920], device='cuda:0')\n",
      "ranks_stage1: [5, 19, 19, 19, 19]\n",
      "ranks_stage2: [6, 17, 18, 10, 13]\n",
      "rerank_loss: tensor([4.2955, 2.8811, 3.6340, 0.2476, 4.9028], device='cuda:0')\n",
      "normal_loss: tensor([4.1142, 3.0219, 4.3425, 0.1025, 6.3666], device='cuda:0')\n",
      "ranks_stage1: [14, 6, 19, 0, 19]\n",
      "ranks_stage2: [12, 5, 10, 0, 19]\n",
      "rerank_loss: tensor([1.9225, 2.2261, 1.0764, 3.3586, 3.4857], device='cuda:0')\n",
      "normal_loss: tensor([1.9565, 2.0728, 1.2981, 3.2878, 3.3999], device='cuda:0')\n",
      "ranks_stage1: [1, 1, 0, 6, 9]\n",
      "ranks_stage2: [1, 1, 0, 6, 9]\n",
      "rerank_loss: tensor([4.4162, 4.5994, 2.2749, 4.9531, 3.0866], device='cuda:0')\n",
      "normal_loss: tensor([5.1587, 4.9182, 2.8213, 7.4512, 6.3345], device='cuda:0')\n",
      "ranks_stage1: [19, 12, 1, 19, 19]\n",
      "ranks_stage2: [17, 12, 1, 18, 8]\n",
      "rerank_loss: tensor([6.1894, 5.1968, 4.0542, 4.6795, 1.3295], device='cuda:0')\n",
      "normal_loss: tensor([6.5348, 5.9077, 7.8420, 4.4376, 6.5594], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 17, 19]\n",
      "ranks_stage2: [19, 19, 7, 15, 0]\n",
      "rerank_loss: tensor([3.5729, 5.4017, 4.9724, 5.1050, 1.3299], device='cuda:0')\n",
      "normal_loss: tensor([3.4826, 7.9726, 7.5357, 6.9707, 1.2328], device='cuda:0')\n",
      "ranks_stage1: [8, 19, 19, 19, 0]\n",
      "ranks_stage2: [8, 19, 17, 17, 0]\n",
      "rerank_loss: tensor([4.4652, 1.2688, 2.8239, 4.2174, 2.4048], device='cuda:0')\n",
      "normal_loss: tensor([5.0677, 1.2621, 3.4764, 5.2963, 5.3480], device='cuda:0')\n",
      "ranks_stage1: [19, 1, 19, 19, 19]\n",
      "ranks_stage2: [16, 1, 4, 19, 3]\n",
      "rerank_loss: tensor([4.0661, 0.4828, 3.4645, 3.6676, 4.2119], device='cuda:0')\n",
      "normal_loss: tensor([4.3363, 0.3146, 4.9257, 3.8373, 4.3275], device='cuda:0')\n",
      "ranks_stage1: [19, 0, 19, 15, 19]\n",
      "ranks_stage2: [8, 0, 12, 11, 17]\n",
      "rerank_loss: tensor([3.6653, 2.7575, 4.5458, 1.4293, 2.9760], device='cuda:0')\n",
      "normal_loss: tensor([3.8550, 2.3896, 6.0918, 1.3004, 3.0103], device='cuda:0')\n",
      "ranks_stage1: [19, 3, 19, 0, 3]\n",
      "ranks_stage2: [17, 3, 16, 0, 4]\n",
      "rerank_loss: tensor([2.3320, 0.5578, 4.3604, 5.3063, 2.5620], device='cuda:0')\n",
      "normal_loss: tensor([2.6028, 0.2368, 5.2514, 6.4973, 2.5918], device='cuda:0')\n",
      "ranks_stage1: [2, 0, 19, 19, 2]\n",
      "ranks_stage2: [2, 0, 15, 12, 3]\n",
      "rerank_loss: tensor([0.4999, 3.8265, 3.0416, 4.4045, 4.3600], device='cuda:0')\n",
      "normal_loss: tensor([0.3001, 6.5257, 4.8277, 6.0886, 5.6189], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 19, 19, 19]\n",
      "ranks_stage2: [0, 6, 9, 19, 19]\n",
      "rerank_loss: tensor([1.5145, 2.1217, 6.3882, 4.5823, 2.7461], device='cuda:0')\n",
      "normal_loss: tensor([1.6650, 2.3456, 8.1203, 5.3768, 2.6328], device='cuda:0')\n",
      "ranks_stage1: [1, 2, 19, 19, 3]\n",
      "ranks_stage2: [1, 2, 19, 15, 4]\n",
      "rerank_loss: tensor([3.3057, 3.6392, 1.7204, 7.1859, 1.9188], device='cuda:0')\n",
      "normal_loss: tensor([5.8350, 7.3706, 2.0759, 6.4560, 5.4948], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 0, 19, 19]\n",
      "ranks_stage2: [7, 5, 0, 18, 0]\n",
      "rerank_loss: tensor([5.4933, 3.8785, 0.4828, 4.2329, 0.7388], device='cuda:0')\n",
      "normal_loss: tensor([5.7506, 3.4047, 0.3146, 4.9775, 0.9275], device='cuda:0')\n",
      "ranks_stage1: [19, 8, 0, 19, 0]\n",
      "ranks_stage2: [19, 12, 0, 17, 0]\n",
      "rerank_loss: tensor([5.6435, 3.6559, 4.6586, 2.1880, 5.0374], device='cuda:0')\n",
      "normal_loss: tensor([7.7103, 3.5345, 5.7212, 2.5227, 6.7738], device='cuda:0')\n",
      "ranks_stage1: [19, 11, 19, 4, 19]\n",
      "ranks_stage2: [19, 7, 19, 3, 12]\n",
      "rerank_loss: tensor([1.9881, 3.4419, 4.0842, 4.1481, 3.8887], device='cuda:0')\n",
      "normal_loss: tensor([1.8336, 3.6408, 4.5405, 4.0749, 6.9649], device='cuda:0')\n",
      "ranks_stage1: [1, 9, 10, 18, 19]\n",
      "ranks_stage2: [1, 6, 9, 15, 14]\n",
      "rerank_loss: tensor([4.3506, 3.5185, 1.5277, 2.1140, 1.6567], device='cuda:0')\n",
      "normal_loss: tensor([6.8387, 2.5333, 1.6733, 3.1633, 1.4123], device='cuda:0')\n",
      "ranks_stage1: [19, 4, 1, 4, 0]\n",
      "ranks_stage2: [16, 9, 1, 2, 0]\n",
      "rerank_loss: tensor([3.7688, 3.9873, 3.5058, 0.4101, 2.0408], device='cuda:0')\n",
      "normal_loss: tensor([2.8086, 4.7004, 5.5833, 0.2991, 1.5955], device='cuda:0')\n",
      "ranks_stage1: [4, 19, 19, 0, 1]\n",
      "ranks_stage2: [5, 12, 11, 0, 1]\n",
      "rerank_loss: tensor([3.7128, 3.2527, 4.3879, 1.5974, 4.7409], device='cuda:0')\n",
      "normal_loss: tensor([5.0934, 4.7409, 4.0513, 5.5118, 6.1187], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 11, 19, 19]\n",
      "ranks_stage2: [9, 9, 16, 0, 17]\n",
      "rerank_loss: tensor([1.7756, 1.3158, 0.6558, 0.7949, 0.1536], device='cuda:0')\n",
      "normal_loss: tensor([7.1746, 0.9859, 0.5943, 0.9615, 0.2300], device='cuda:0')\n",
      "ranks_stage1: [19, 0, 0, 0, 0]\n",
      "ranks_stage2: [2, 0, 0, 0, 0]\n",
      "rerank_loss: tensor([0.9781, 2.7969, 0.1808, 3.4497, 1.2147], device='cuda:0')\n",
      "normal_loss: tensor([0.8088, 5.5129, 0.0556, 5.6714, 1.1206], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 0, 19, 0]\n",
      "ranks_stage2: [0, 2, 0, 10, 0]\n",
      "rerank_loss: tensor([3.1981e+00, 7.0903e-01, 3.2477e+00, 3.1505e-03, 3.4613e+00],\n",
      "       device='cuda:0')\n",
      "normal_loss: tensor([4.8034e+00, 5.6252e-01, 3.2995e+00, 2.0901e-03, 2.9078e+00],\n",
      "       device='cuda:0')\n",
      "ranks_stage1: [19, 0, 4, 0, 6]\n",
      "ranks_stage2: [8, 0, 4, 0, 9]\n",
      "rerank_loss: tensor([4.1077, 1.4244, 5.2615, 4.2167, 3.2858], device='cuda:0')\n",
      "normal_loss: tensor([3.4535, 1.5635, 7.5320, 6.2227, 6.0004], device='cuda:0')\n",
      "ranks_stage1: [7, 1, 19, 19, 19]\n",
      "ranks_stage2: [10, 0, 19, 18, 8]\n",
      "rerank_loss: tensor([5.3724, 2.3017, 3.8052, 2.6570, 2.5986], device='cuda:0')\n",
      "normal_loss: tensor([6.5341, 2.0126, 5.5997, 2.0404, 4.7486], device='cuda:0')\n",
      "ranks_stage1: [19, 2, 19, 3, 19]\n",
      "ranks_stage2: [19, 2, 19, 5, 1]\n",
      "rerank_loss: tensor([3.3228, 1.4482, 3.1032, 1.2471, 1.1199], device='cuda:0')\n",
      "normal_loss: tensor([3.1963, 1.7152, 4.4789, 1.2079, 0.8878], device='cuda:0')\n",
      "ranks_stage1: [6, 1, 19, 1, 0]\n",
      "ranks_stage2: [4, 1, 12, 1, 0]\n",
      "rerank_loss: tensor([1.3224, 4.7593, 3.1155, 4.9556, 0.0268], device='cuda:0')\n",
      "normal_loss: tensor([1.4659, 7.6772, 2.5075, 8.5141, 0.0701], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 4, 19, 0]\n",
      "ranks_stage2: [0, 15, 6, 15, 0]\n",
      "rerank_loss: tensor([3.4356, 3.5082, 4.5056, 4.3138, 7.8696], device='cuda:0')\n",
      "normal_loss: tensor([3.8575, 7.3526, 4.6625, 4.5195, 8.2256], device='cuda:0')\n",
      "ranks_stage1: [15, 19, 19, 19, 19]\n",
      "ranks_stage2: [9, 12, 17, 10, 19]\n",
      "rerank_loss: tensor([4.3139, 1.4573, 3.2781, 3.3779, 1.7628], device='cuda:0')\n",
      "normal_loss: tensor([5.9922, 1.2966, 5.9106, 2.9425, 1.6182], device='cuda:0')\n",
      "ranks_stage1: [19, 0, 19, 7, 1]\n",
      "ranks_stage2: [17, 0, 10, 8, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rerank_loss: tensor([2.4362, 4.4805, 1.5887, 4.4401, 2.3216], device='cuda:0')\n",
      "normal_loss: tensor([1.9764, 5.3079, 1.4148, 6.4867, 2.9774], device='cuda:0')\n",
      "ranks_stage1: [2, 19, 0, 19, 4]\n",
      "ranks_stage2: [2, 15, 0, 15, 2]\n",
      "rerank_loss: tensor([0.8098, 0.9130, 1.8284, 2.4341, 2.5226], device='cuda:0')\n",
      "normal_loss: tensor([1.0256, 0.7138, 2.7832, 4.2641, 2.2188], device='cuda:0')\n",
      "ranks_stage1: [0, 0, 1, 19, 2]\n",
      "ranks_stage2: [0, 0, 1, 2, 3]\n",
      "rerank_loss: tensor([4.9060, 1.9892, 3.8972, 3.7233, 1.6379], device='cuda:0')\n",
      "normal_loss: tensor([7.9648, 2.4831, 6.6280, 3.4957, 1.4975], device='cuda:0')\n",
      "ranks_stage1: [19, 1, 19, 12, 0]\n",
      "ranks_stage2: [9, 2, 10, 13, 1]\n",
      "rerank_loss: tensor([2.6091, 1.0450, 1.9943, 3.0801, 2.8382], device='cuda:0')\n",
      "normal_loss: tensor([2.4305, 0.8470, 1.8174, 3.0470, 6.0331], device='cuda:0')\n",
      "ranks_stage1: [2, 0, 1, 5, 19]\n",
      "ranks_stage2: [2, 0, 1, 9, 5]\n",
      "rerank_loss: tensor([3.0096, 5.2559, 3.6233, 3.9639, 7.0518], device='cuda:0')\n",
      "normal_loss: tensor([5.7622, 5.9190, 4.0383, 6.0600, 8.8603], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 19, 19]\n",
      "ranks_stage2: [6, 19, 9, 8, 18]\n",
      "rerank_loss: tensor([2.5742, 4.0277, 1.8564, 2.9414, 1.2170], device='cuda:0')\n",
      "normal_loss: tensor([6.6525, 5.3770, 4.8618, 5.0162, 1.2815], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 6, 1]\n",
      "ranks_stage2: [4, 19, 1, 5, 1]\n",
      "rerank_loss: tensor([1.4230, 3.2599, 3.9429, 1.9059, 3.5652], device='cuda:0')\n",
      "normal_loss: tensor([1.7336, 3.5664, 3.8261, 1.6903, 4.6020], device='cuda:0')\n",
      "ranks_stage1: [1, 8, 19, 0, 19]\n",
      "ranks_stage2: [0, 6, 16, 1, 11]\n",
      "rerank_loss: tensor([3.4495, 4.4328, 3.5723, 5.1925, 0.3852], device='cuda:0')\n",
      "normal_loss: tensor([6.0302, 6.8516, 4.0048, 6.8635, 0.1705], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 13, 19, 0]\n",
      "ranks_stage2: [8, 5, 10, 16, 0]\n",
      "rerank_loss: tensor([1.4990, 3.8108, 2.2515, 1.2170, 2.9878], device='cuda:0')\n",
      "normal_loss: tensor([1.8070, 5.0612, 2.4925, 1.2262, 3.2891], device='cuda:0')\n",
      "ranks_stage1: [1, 19, 2, 0, 15]\n",
      "ranks_stage2: [1, 13, 2, 0, 12]\n",
      "rerank_loss: tensor([3.8888, 5.1683, 3.8579, 3.8147, 3.4038], device='cuda:0')\n",
      "normal_loss: tensor([4.1155, 7.5699, 6.5487, 6.3473, 2.9239], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 19, 5]\n",
      "ranks_stage2: [10, 17, 15, 14, 7]\n",
      "rerank_loss: tensor([0.5792, 0.7297, 1.4879, 3.6526, 0.6515], device='cuda:0')\n",
      "normal_loss: tensor([0.6639, 0.8237, 7.0626, 3.6396, 0.5658], device='cuda:0')\n",
      "ranks_stage1: [0, 0, 19, 13, 0]\n",
      "ranks_stage2: [0, 0, 0, 11, 0]\n",
      "rerank_loss: tensor([4.0116, 4.3310, 4.0137, 4.8257, 2.6377], device='cuda:0')\n",
      "normal_loss: tensor([4.7300, 6.0643, 4.9250, 7.3839, 1.9919], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 19, 3]\n",
      "ranks_stage2: [15, 19, 16, 13, 3]\n",
      "rerank_loss: tensor([3.5746, 0.5332, 2.9097, 2.7271, 1.2849], device='cuda:0')\n",
      "normal_loss: tensor([3.1602, 0.5597, 4.2540, 4.1548, 1.0942], device='cuda:0')\n",
      "ranks_stage1: [8, 0, 19, 19, 0]\n",
      "ranks_stage2: [8, 0, 4, 5, 0]\n",
      "rerank_loss: tensor([0.8678, 3.4034, 0.1885, 4.6633, 4.1980], device='cuda:0')\n",
      "normal_loss: tensor([0.7988, 5.6673, 0.1756, 5.4965, 6.3596], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 0, 19, 19]\n",
      "ranks_stage2: [0, 7, 0, 14, 14]\n",
      "rerank_loss: tensor([0.1001, 3.0830, 6.4163, 4.3087, 3.8827], device='cuda:0')\n",
      "normal_loss: tensor([0.1053, 5.1406, 6.8217, 5.9633, 4.5945], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 19, 19, 19]\n",
      "ranks_stage2: [0, 4, 19, 9, 18]\n",
      "rerank_loss: tensor([0.8601, 1.2458, 3.8404, 1.0626, 2.0017], device='cuda:0')\n",
      "normal_loss: tensor([0.9157, 1.4631, 3.8530, 1.0724, 4.4914], device='cuda:0')\n",
      "ranks_stage1: [0, 0, 11, 0, 19]\n",
      "ranks_stage2: [0, 0, 11, 1, 1]\n",
      "rerank_loss: tensor([1.8089, 1.6006, 4.5436, 0.1602, 3.6459], device='cuda:0')\n",
      "normal_loss: tensor([1.7657, 1.4445, 6.4100, 0.1490, 4.1084], device='cuda:0')\n",
      "ranks_stage1: [1, 1, 19, 0, 19]\n",
      "ranks_stage2: [1, 2, 19, 0, 11]\n",
      "rerank_loss: tensor([0.3346, 5.4128, 1.7476, 0.2989, 0.5599], device='cuda:0')\n",
      "normal_loss: tensor([0.0069, 6.4214, 1.7447, 0.2793, 0.3843], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 2, 0, 0]\n",
      "ranks_stage2: [0, 19, 2, 0, 0]\n",
      "rerank_loss: tensor([3.2689, 0.3411, 2.5761, 4.8332, 5.3961], device='cuda:0')\n",
      "normal_loss: tensor([3.2009, 0.3860, 2.9123, 4.8685, 6.6226], device='cuda:0')\n",
      "ranks_stage1: [5, 0, 4, 19, 19]\n",
      "ranks_stage2: [6, 0, 4, 19, 18]\n",
      "rerank_loss: tensor([3.2349, 1.9786, 1.2207, 1.8911, 0.5217], device='cuda:0')\n",
      "normal_loss: tensor([6.6021, 3.3623, 1.0953, 2.0572, 0.2703], device='cuda:0')\n",
      "ranks_stage1: [19, 1, 0, 1, 0]\n",
      "ranks_stage2: [8, 1, 0, 1, 0]\n",
      "rerank_loss: tensor([2.7833, 0.4888, 4.9737, 4.4683, 2.4458], device='cuda:0')\n",
      "normal_loss: tensor([4.2869, 0.4574, 5.8711, 4.3350, 2.3850], device='cuda:0')\n",
      "ranks_stage1: [19, 0, 18, 9, 1]\n",
      "ranks_stage2: [4, 0, 16, 9, 4]\n",
      "rerank_loss: tensor([2.6939, 1.8463, 1.8138, 4.7871, 2.0793], device='cuda:0')\n",
      "normal_loss: tensor([2.7631, 1.6961, 1.4100, 4.2145, 2.1182], device='cuda:0')\n",
      "ranks_stage1: [2, 0, 0, 6, 1]\n",
      "ranks_stage2: [2, 0, 0, 6, 1]\n",
      "rerank_loss: tensor([2.1459, 4.2050, 1.7046, 2.9411, 3.6764], device='cuda:0')\n",
      "normal_loss: tensor([3.8378, 6.1268, 1.8479, 4.6841, 5.4095], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 1, 19, 19]\n",
      "ranks_stage2: [1, 15, 0, 7, 5]\n",
      "rerank_loss: tensor([4.1214, 4.0484, 0.6318, 4.3908, 2.0189], device='cuda:0')\n",
      "normal_loss: tensor([5.5289, 4.0832, 0.4445, 6.4101, 1.5052], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 0, 19, 1]\n",
      "ranks_stage2: [19, 19, 0, 19, 2]\n",
      "rerank_loss: tensor([3.4820, 3.2865, 1.1403, 3.1441, 0.6571], device='cuda:0')\n",
      "normal_loss: tensor([3.4182, 4.6406, 1.1530, 7.0025, 0.7024], device='cuda:0')\n",
      "ranks_stage1: [5, 19, 1, 19, 0]\n",
      "ranks_stage2: [5, 9, 1, 5, 0]\n",
      "rerank_loss: tensor([0.0775, 1.2786, 3.6814, 2.6072, 2.9443], device='cuda:0')\n",
      "normal_loss: tensor([0.1610, 1.1652, 7.3694, 2.3886, 8.4407], device='cuda:0')\n",
      "ranks_stage1: [0, 0, 19, 3, 19]\n",
      "ranks_stage2: [0, 0, 4, 3, 3]\n",
      "rerank_loss: tensor([3.7519, 3.6853, 0.0295, 3.9914, 0.2317], device='cuda:0')\n",
      "normal_loss: tensor([4.2370, 3.8411, 0.2356, 6.4292, 0.9679], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 0, 19, 0]\n",
      "ranks_stage2: [10, 15, 0, 13, 0]\n",
      "rerank_loss: tensor([2.7499, 4.9405, 1.7684, 0.0165, 1.1546], device='cuda:0')\n",
      "normal_loss: tensor([3.0474, 5.9256, 1.3037, 0.0132, 1.0013], device='cuda:0')\n",
      "ranks_stage1: [10, 19, 1, 0, 0]\n",
      "ranks_stage2: [9, 19, 1, 0, 0]\n",
      "rerank_loss: tensor([2.8135, 2.4689, 4.2194, 3.8920, 4.6840], device='cuda:0')\n",
      "normal_loss: tensor([4.8523, 1.9484, 6.9648, 4.3485, 7.3473], device='cuda:0')\n",
      "ranks_stage1: [19, 1, 19, 12, 19]\n",
      "ranks_stage2: [5, 4, 18, 12, 13]\n",
      "rerank_loss: tensor([1.1647, 3.7456, 4.9680, 2.2092, 3.8154], device='cuda:0')\n",
      "normal_loss: tensor([1.2147, 5.1820, 5.5187, 1.8449, 4.5656], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 8, 2, 19]\n",
      "ranks_stage2: [0, 12, 6, 2, 13]\n",
      "rerank_loss: tensor([2.3358, 0.6782, 4.0379, 2.4910, 0.2359], device='cuda:0')\n",
      "normal_loss: tensor([2.3005, 0.4475, 6.4366, 7.3544, 0.0845], device='cuda:0')\n",
      "ranks_stage1: [2, 0, 19, 19, 0]\n",
      "ranks_stage2: [2, 0, 16, 3, 0]\n",
      "rerank_loss: tensor([3.4199, 3.2088, 1.7104, 5.2397, 3.4251], device='cuda:0')\n",
      "normal_loss: tensor([5.1664, 5.7822, 2.6265, 6.3570, 7.0819], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 1, 19, 19]\n",
      "ranks_stage2: [8, 3, 1, 17, 11]\n",
      "rerank_loss: tensor([2.8990, 4.3761, 0.4771, 1.0186, 3.0087], device='cuda:0')\n",
      "normal_loss: tensor([4.2582, 6.1513, 0.1176, 1.2327, 3.7363], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 0, 0, 19]\n",
      "ranks_stage2: [5, 16, 0, 0, 6]\n",
      "rerank_loss: tensor([1.6875, 0.4883, 5.6255, 2.6625, 3.5064], device='cuda:0')\n",
      "normal_loss: tensor([1.4876, 0.2169, 5.6652, 2.6773, 4.6139], device='cuda:0')\n",
      "ranks_stage1: [1, 0, 19, 4, 19]\n",
      "ranks_stage2: [1, 0, 17, 4, 11]\n",
      "rerank_loss: tensor([1.0314, 0.8858, 4.3779, 1.8527, 2.4100], device='cuda:0')\n",
      "normal_loss: tensor([1.4322, 0.6778, 4.4474, 1.9286, 2.7379], device='cuda:0')\n",
      "ranks_stage1: [0, 0, 16, 1, 5]\n",
      "ranks_stage2: [0, 0, 18, 1, 3]\n",
      "rerank_loss: tensor([0.3802, 2.1372, 2.4113, 1.0559, 3.8907], device='cuda:0')\n",
      "normal_loss: tensor([0.1544, 2.3489, 2.1819, 0.8396, 5.2231], device='cuda:0')\n",
      "ranks_stage1: [0, 2, 1, 1, 19]\n",
      "ranks_stage2: [0, 2, 0, 1, 14]\n",
      "rerank_loss: tensor([4.6725, 4.3407, 1.1908, 0.3871, 1.9912], device='cuda:0')\n",
      "normal_loss: tensor([5.4562, 5.9162, 1.1155, 0.3711, 1.8783], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 1, 0, 1]\n",
      "ranks_stage2: [9, 17, 1, 0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rerank_loss: tensor([0.1852, 2.6631, 7.6209, 5.4579, 4.1735], device='cuda:0')\n",
      "normal_loss: tensor([1.1859, 1.1177, 7.4793, 4.1737, 3.9832], device='cuda:0')\n",
      "ranks_stage1: [0, 1, 19, 13, 12]\n",
      "ranks_stage2: [0, 1, 19, 13, 14]\n",
      "rerank_loss: tensor([1.6750, 0.0042, 1.7767, 1.5351, 0.6876], device='cuda:0')\n",
      "normal_loss: tensor([1.9364, 0.0065, 1.7736, 1.3810, 0.4297], device='cuda:0')\n",
      "ranks_stage1: [1, 0, 1, 0, 0]\n",
      "ranks_stage2: [1, 0, 1, 1, 0]\n",
      "rerank_loss: tensor([5.6280, 0.2494, 3.0909, 4.6833, 3.2236], device='cuda:0')\n",
      "normal_loss: tensor([6.9606, 0.2095, 5.3746, 6.0167, 5.3425], device='cuda:0')\n",
      "ranks_stage1: [19, 0, 19, 19, 19]\n",
      "ranks_stage2: [19, 0, 5, 18, 7]\n",
      "rerank_loss: tensor([2.0642, 1.3654, 2.6942, 5.8503, 5.6522], device='cuda:0')\n",
      "normal_loss: tensor([3.2007, 2.0254, 2.5499, 6.7583, 7.7974], device='cuda:0')\n",
      "ranks_stage1: [1, 3, 2, 19, 19]\n",
      "ranks_stage2: [1, 1, 2, 19, 17]\n",
      "rerank_loss: tensor([4.1270, 5.2383, 0.6075, 0.3011, 0.3566], device='cuda:0')\n",
      "normal_loss: tensor([4.8290, 5.7869, 0.1231, 0.0354, 0.1007], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 0, 0, 0]\n",
      "ranks_stage2: [17, 18, 0, 0, 0]\n",
      "rerank_loss: tensor([4.8532, 3.3465, 4.3164, 3.6490, 3.4720], device='cuda:0')\n",
      "normal_loss: tensor([5.2672, 4.3697, 4.3262, 3.8389, 3.4414], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 6, 17, 10]\n",
      "ranks_stage2: [16, 8, 5, 18, 13]\n",
      "rerank_loss: tensor([2.7954, 5.1429, 3.2151, 4.9182, 3.7575], device='cuda:0')\n",
      "normal_loss: tensor([8.2371, 8.5913, 5.6500, 4.9942, 3.3726], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 18, 12]\n",
      "ranks_stage2: [3, 18, 7, 14, 13]\n",
      "rerank_loss: tensor([2.5722, 4.2881, 1.4508, 3.9434, 4.8338], device='cuda:0')\n",
      "normal_loss: tensor([1.2052, 5.1612, 1.3628, 3.6152, 5.3660], device='cuda:0')\n",
      "ranks_stage1: [1, 19, 0, 19, 19]\n",
      "ranks_stage2: [1, 19, 1, 16, 19]\n",
      "rerank_loss: tensor([2.2311, 4.0522, 1.9283, 5.1251, 3.6392], device='cuda:0')\n",
      "normal_loss: tensor([4.6825, 4.9318, 1.9708, 7.1060, 4.3145], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 1, 19, 19]\n",
      "ranks_stage2: [1, 15, 1, 18, 10]\n",
      "rerank_loss: tensor([3.5779, 1.1976, 2.2372, 0.0050, 2.3890], device='cuda:0')\n",
      "normal_loss: tensor([4.5754, 7.5313, 5.1695, 0.0081, 2.1652], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 0, 4]\n",
      "ranks_stage2: [14, 0, 0, 0, 4]\n",
      "rerank_loss: tensor([0.9931, 3.7607, 4.8549, 2.2565, 2.7699], device='cuda:0')\n",
      "normal_loss: tensor([0.8786, 5.8644, 6.1963, 1.9361, 2.8622], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 19, 2, 4]\n",
      "ranks_stage2: [0, 19, 18, 3, 4]\n",
      "rerank_loss: tensor([4.2642, 1.5886, 1.5788, 3.1373, 0.2055], device='cuda:0')\n",
      "normal_loss: tensor([4.9555, 1.7372, 1.2856, 5.0628, 0.2348], device='cuda:0')\n",
      "ranks_stage1: [19, 0, 1, 19, 0]\n",
      "ranks_stage2: [17, 0, 1, 5, 0]\n",
      "rerank_loss: tensor([2.3012, 5.2544, 4.5789, 1.9466, 2.5730], device='cuda:0')\n",
      "normal_loss: tensor([6.8324, 5.9154, 4.1555, 1.5055, 5.1742], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 16, 2, 19]\n",
      "ranks_stage2: [2, 18, 15, 2, 4]\n",
      "rerank_loss: tensor([5.2236, 3.7842, 0.1203, 3.1120, 2.8770], device='cuda:0')\n",
      "normal_loss: tensor([6.1819, 5.2786, 0.2156, 3.2309, 7.2714], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 0, 6, 19]\n",
      "ranks_stage2: [19, 10, 0, 6, 6]\n",
      "rerank_loss: tensor([2.7120, 0.0129, 2.3451, 1.8392, 4.8941], device='cuda:0')\n",
      "normal_loss: tensor([2.7849, 0.0130, 2.7105, 1.3931, 5.9729], device='cuda:0')\n",
      "ranks_stage1: [3, 0, 1, 1, 19]\n",
      "ranks_stage2: [3, 0, 1, 1, 16]\n",
      "rerank_loss: tensor([3.8501, 2.9314, 4.4663, 3.7612, 3.4055], device='cuda:0')\n",
      "normal_loss: tensor([3.9818, 3.0534, 6.8105, 6.6291, 2.0888], device='cuda:0')\n",
      "ranks_stage1: [12, 6, 19, 19, 2]\n",
      "ranks_stage2: [11, 6, 6, 15, 8]\n",
      "rerank_loss: tensor([0.9889, 6.1993, 2.6676, 1.2754, 3.8929], device='cuda:0')\n",
      "normal_loss: tensor([1.0498, 4.0291, 4.3777, 1.4691, 6.5664], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 1, 1, 19]\n",
      "ranks_stage2: [0, 12, 1, 1, 7]\n",
      "rerank_loss: tensor([2.4074, 5.3852, 3.6330, 3.7008, 2.0100], device='cuda:0')\n",
      "normal_loss: tensor([5.7375, 5.8479, 8.7011, 4.8371, 1.8298], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 19, 19, 1]\n",
      "ranks_stage2: [1, 16, 11, 16, 2]\n",
      "rerank_loss: tensor([2.5929, 4.7226, 2.0994, 2.2313, 4.0375], device='cuda:0')\n",
      "normal_loss: tensor([2.7927, 5.0284, 1.4414, 2.5884, 5.6859], device='cuda:0')\n",
      "ranks_stage1: [3, 19, 1, 2, 19]\n",
      "ranks_stage2: [3, 18, 1, 2, 17]\n",
      "rerank_loss: tensor([0.0310, 4.8165, 0.5259, 4.6147, 0.6539], device='cuda:0')\n",
      "normal_loss: tensor([0.0081, 7.4990, 0.6953, 5.4771, 0.4195], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 0, 19, 0]\n",
      "ranks_stage2: [0, 14, 0, 19, 0]\n",
      "rerank_loss: tensor([4.0500, 0.0458, 3.8734, 0.0875, 1.2407], device='cuda:0')\n",
      "normal_loss: tensor([4.9646, 0.0345, 5.5565, 0.1265, 0.9891], device='cuda:0')\n",
      "ranks_stage1: [19, 0, 19, 0, 0]\n",
      "ranks_stage2: [17, 0, 3, 0, 0]\n",
      "rerank_loss: tensor([2.2795, 4.3576, 6.1602, 1.0145, 4.8100], device='cuda:0')\n",
      "normal_loss: tensor([1.9150, 5.2989, 7.8075, 0.3978, 9.5833], device='cuda:0')\n",
      "ranks_stage1: [2, 19, 19, 0, 19]\n",
      "ranks_stage2: [2, 16, 19, 0, 10]\n",
      "rerank_loss: tensor([0.9729, 0.1310, 2.0722, 4.6648, 0.6135], device='cuda:0')\n",
      "normal_loss: tensor([1.8398, 0.4359, 1.9750, 4.6242, 9.6359], device='cuda:0')\n",
      "ranks_stage1: [0, 0, 2, 19, 19]\n",
      "ranks_stage2: [0, 0, 2, 18, 0]\n",
      "rerank_loss: tensor([0.5930, 1.9741, 4.9831, 2.7894, 1.8296], device='cuda:0')\n",
      "normal_loss: tensor([0.2804, 6.0881, 7.1189, 2.7742, 7.3046], device='cuda:0')\n",
      "ranks_stage1: [0, 19, 7, 6, 19]\n",
      "ranks_stage2: [0, 1, 8, 6, 0]\n",
      "rerank_loss: tensor([5.4735, 3.5349, 1.8215, 5.4062, 2.0746], device='cuda:0')\n",
      "normal_loss: tensor([8.7104, 6.2169, 1.8606, 5.1718, 2.2124], device='cuda:0')\n",
      "ranks_stage1: [19, 19, 2, 19, 2]\n",
      "ranks_stage2: [17, 10, 2, 16, 2]\n",
      "rerank_loss: tensor([1.1631, 6.3237, 1.0858, 3.7268, 3.5081], device='cuda:0')\n",
      "normal_loss: tensor([1.2960, 5.8255, 1.0508, 5.9551, 3.9477], device='cuda:0')\n",
      "ranks_stage1: [1, 19, 0, 19, 19]\n",
      "ranks_stage2: [1, 18, 0, 9, 19]\n",
      "  Validation Loss: 5.91\n",
      "  Average Validation normal_loss: 3.31\n",
      "  Average Validation rerank_loss: 2.60\n",
      "  Validation took: 0:25:22\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# ========================================\n",
    "#               Validation\n",
    "# ========================================\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total_eval_loss = 0\n",
    "total_eval_normal_loss = 0\n",
    "total_eval_normal_loss_in_rerank_place = 0\n",
    "total_eval_rerank_loss = 0\n",
    "\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "stage1_gt_ranking = []\n",
    "stage2_gt_ranking = []\n",
    "for batch in inside_validation_dataloader:\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        outputs = model(  input_ids=batch,         #batch_input_ids\n",
    "                          labels=batch,            #batch_labels\n",
    "                          is_training=False,\n",
    "                       )\n",
    "\n",
    "        normal_loss = outputs[\"normal_loss_in_rerank_place\"].mean()\n",
    "        rerank_loss = outputs[\"rerank_loss\"].mean()\n",
    "        stage1_gt_ranking.extend(outputs[\"ranks_stage1\"])\n",
    "        stage2_gt_ranking.extend(outputs[\"ranks_stage2\"])\n",
    "\n",
    "        loss = normal_loss + rerank_loss\n",
    "\n",
    "    batch_loss = loss.item()\n",
    "    total_eval_loss += batch_loss        \n",
    "\n",
    "    batch_normal_loss = normal_loss.item()\n",
    "    total_eval_normal_loss += batch_normal_loss\n",
    "\n",
    "    batch_rerank_loss = rerank_loss.item()\n",
    "    total_eval_rerank_loss += batch_rerank_loss\n",
    "\n",
    "avg_val_loss = total_eval_loss / len(inside_validation_dataloader)\n",
    "avg_val_normal_loss = total_eval_normal_loss / len(inside_validation_dataloader)          \n",
    "avg_val_rerank_loss = total_eval_rerank_loss / len(inside_validation_dataloader)    \n",
    "\n",
    "validation_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "print(\"  Average Validation normal_loss: {0:.2f}\".format(avg_val_normal_loss))\n",
    "print(\"  Average Validation rerank_loss: {0:.2f}\".format(avg_val_rerank_loss))\n",
    "print(\"  Validation took: {:}\".format(validation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "imported-christopher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal MRR is  0.43380786470336496\n",
      "rerank MRR is  0.46583580429337307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mean_reciprocal_rank(gt_ranks, CAN_NUM=5):\n",
    "    rs = []\n",
    "    for i in range(len(gt_ranks)):\n",
    "        tmp = np.zeros(CAN_NUM)\n",
    "        tmp[gt_ranks[i]] = 1\n",
    "        rs.append(tmp)\n",
    "    \n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs]) \n",
    "\n",
    "\n",
    "print(\"normal MRR is \", mean_reciprocal_rank(gt_ranks=stage1_gt_ranking, CAN_NUM=20))\n",
    "print(\"rerank MRR is \", mean_reciprocal_rank(gt_ranks=stage2_gt_ranking, CAN_NUM=20))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "following-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_gt_in_candidates_cases = []\n",
    "stage1_gt_not_in_candidates_cases = []\n",
    "stage2_gt_in_candidates_cases = []\n",
    "stage2_gt_not_in_candidates_cases = []\n",
    "for i in range(len(stage1_gt_ranking)):\n",
    "    if stage1_gt_ranking[i] == 19:\n",
    "        stage1_gt_not_in_candidates_cases.append(stage1_gt_ranking[i])\n",
    "        stage2_gt_not_in_candidates_cases.append(stage2_gt_ranking[i])\n",
    "    else:\n",
    "        stage1_gt_in_candidates_cases.append(stage1_gt_ranking[i])\n",
    "        stage2_gt_in_candidates_cases.append(stage2_gt_ranking[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "personal-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_in_candidates_cases normal MRR is  0.6504284335209369\n",
      "gt_in_candidates_cases rerank MRR is  0.6553313709017413\n"
     ]
    }
   ],
   "source": [
    "print(\"gt_in_candidates_cases normal MRR is \", mean_reciprocal_rank(gt_ranks=stage1_gt_in_candidates_cases, CAN_NUM=20))\n",
    "print(\"gt_in_candidates_cases rerank MRR is \", mean_reciprocal_rank(gt_ranks=stage2_gt_in_candidates_cases, CAN_NUM=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "statewide-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_not_in_candidates_cases normal MRR is  0.05000000000000002\n",
      "gt_not_in_candidates_cases rerank MRR is  0.1300879610127941\n"
     ]
    }
   ],
   "source": [
    "print(\"gt_not_in_candidates_cases normal MRR is \", mean_reciprocal_rank(gt_ranks=stage1_gt_not_in_candidates_cases, CAN_NUM=20))\n",
    "print(\"gt_not_in_candidates_cases rerank MRR is \", mean_reciprocal_rank(gt_ranks=stage2_gt_not_in_candidates_cases, CAN_NUM=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-humidity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
